var documenterSearchIndex = {"docs":
[{"location":"references/#all_ref","page":"References","title":"References","text":"","category":"section"},{"location":"references/#[BAT14]","page":"References","title":"[BAT14]","text":"<ul><li>\n\nK.-J. Bathe, Finite Element Procedures, Watertown, USA, 2014.\n\n<li style=\"list-style: none\"><details>\n<summary>bibtex</summary>\n\n@book{Bathe2014,\n\taddress = {Watertown, USA},\n\tauthor = {Bathe, Klaus-J{\\\"{u}}rgen},\n\tedition = {2},\n\ttitle = {{Finite Element Procedures}},\n\tyear = {2014},\n  url  = {https://web.mit.edu/kjb/www/Books/FEP_2nd_Edition_4th_Printing.pdf}\n}\n\n</details></li></ul>\n\n","category":"section"},{"location":"references/#[HLA13]","page":"References","title":"[HLA13]","text":"<ul><li>\n\nM. Hladík. Bounds on eigenvalues of real and complex interval matrices. Appl. Math. Comput., 219(10):5584–5591, 2013.\n\n<li style=\"list-style: none\"><details>\n<summary>bibtex</summary>\n\n@article{Hla2013a,\n author = \"Milan Hlad\\'{\\i}k\",\n title = \"Bounds on eigenvalues of real and complex interval matrices\",\n journal = \"Appl. Math. Comput.\",\n fjournal = \"Applied Mathematics and Computation\",\n volume = \"219\",\n number = \"10\",\n pages = \"5584-5591\",\n year = \"2013\",\n issn = \"0096-3003\",\n doi = \"10.1016/j.amc.2012.11.075\",\n}\n\n</details></li></ul>\n\n","category":"section"},{"location":"references/#[HOR19]","page":"References","title":"[HOR19]","text":"<ul><li>\n\nJ. Horácek, Interval Linear and Nonlinear Systems, PhD dissertation, 2019\n\n<li style=\"list-style: none\"><details>\n<summary>bibtex</summary>\n\n@article{horavcek2019interval,\n  title={Interval linear and nonlinear systems},\n  author={Hor{\\'a}{\\v{c}}ek, Jaroslav},\n  year={2019},\n  publisher={Univerzita Karlova, Matematicko-fyzik{\\'a}ln{\\'\\i} fakulta}\n}\n\n</details></li></ul>\n\n","category":"section"},{"location":"references/#[JAU14]","page":"References","title":"[JAU14]","text":"<ul><li>\n\nL. Jaulin and B. Desrochers, Introduction to the algebra of separators with application to path planning, Engineering Applications of Artificial Intelligence 33 (2014): 141-147\n\n<li style=\"list-style: none\"><details>\n<summary>bibtex</summary>\n\n@article{jaulin2014introduction,\n  title={Introduction to the algebra of separators with application to path planning},\n  author={Jaulin, Luc and Desrochers, Beno{\\^\\i}t},\n  journal={Engineering Applications of Artificial Intelligence},\n  volume={33},\n  pages={141--147},\n  year={2014},\n  publisher={Elsevier}\n}\n\n</details></li></ul>\n\n","category":"section"},{"location":"references/#[NEU90]","page":"References","title":"[NEU90]","text":"<ul><li>\n\nA. Neumaier, Interval methods for systems of equations, Cambridge university press, 1990\n\n<li style=\"list-style: none\"><details>\n<summary>bibtex</summary>\n\n@book{neumaier1990interval,\n  title={Interval methods for systems of equations},\n  author={Neumaier, Arnold and Neumaier, Arnold},\n  number={37},\n  year={1990},\n  publisher={Cambridge university press}\n}\n\n</details></li></ul>\n\n","category":"section"},{"location":"references/#[OET64]","page":"References","title":"[OET64]","text":"<ul><li>\n\nW. Oettli and W. Prager, Compatibility of approximate solution of linear equations with given error bounds for coefficients and right-hand sides, Numerische Mathematik, 6(1):405–409, 1964.\n\n<li style=\"list-style: none\"><details>\n<summary>bibtex</summary>\n\n@article{oettli1964compatibility,\n  title={Compatibility of approximate solution of linear equations with given error bounds for coefficients and right-hand sides},\n  author={Oettli, Werner and Prager, William},\n  journal={Numerische Mathematik},\n  volume={6},\n  number={1},\n  pages={405--409},\n  year={1964},\n  publisher={Springer}\n}\n\n</details></li></ul>\n\n","category":"section"},{"location":"references/#[ROH06]","page":"References","title":"[ROH06]","text":"<ul><li>\n\nJ. Rohn. Solvability of systems of interval linear equations and inequalities, Linear optimization problems with inexact data, pages 35–77. Springer, 2006\n\n<li style=\"list-style: none\"><details>\n<summary>bibtex</summary>\n\n@incollection{rohn2006solvability,\n  title={Solvability of systems of interval linear equations and inequalities},\n  author={Rohn, Jir{\\i}},\n  booktitle={Linear optimization problems with inexact data},\n  pages={35--77},\n  year={2006},\n  publisher={Springer}\n}\n\n</details></li></ul>\n\n","category":"section"},{"location":"references/#[ROH95]","page":"References","title":"[ROH95]","text":"<ul><li>\n\nJ. Rohn and V. Kreinovich. Computing exact componentwise bounds on solutions of lineary systems with interval data is NP-hard. SIAM Journal on Matrix Analysis and Applications, 16(2):415–420, 1995.\n\n<li style=\"list-style: none\"><details>\n<summary>bibtex</summary>\n\n@article{rohn1995computing,\n  title={Computing exact componentwise bounds on solutions of lineary systems with interval data is NP-hard},\n  author={Rohn, Jiri and Kreinovich, Vladik},\n  journal={SIAM Journal on Matrix Analysis and Applications},\n  volume={16},\n  number={2},\n  pages={415--420},\n  year={1995},\n  publisher={SIAM}\n}\n\n</details></li></ul>\n\n","category":"section"},{"location":"references/#[RUM10]","page":"References","title":"[RUM10]","text":"<ul><li>\n\nS.M. Rump, Verification methods: Rigorous results using floating-point arithmetic, Acta Numerica, 19:287–449, 2010\n\n<li style=\"list-style: none\"><details>\n<summary>bibtex</summary>\n\n@article{rump2010verification,\n  title={Verification methods: Rigorous results using floating-point arithmetic},\n  author={Rump, Siegfried M},\n  journal={Acta Numerica},\n  volume={19},\n  pages={287--449},\n  year={2010},\n  publisher={Cambridge University Press}\n}\n\n</details></li></ul>\n\n","category":"section"},{"location":"references/#[RUM01]","page":"References","title":"[RUM01]","text":"<ul><li>\n\nRump, Siegfried M. Computational error bounds for multiple or nearly multiple eigenvalues, Linear algebra and its applications 324.1-3 (2001): 209-226.\n\n<li style=\"list-style: none\"><details>\n<summary>bibtex</summary>\n\n@article{rump2001computational,\n  title={Computational error bounds for multiple or nearly multiple eigenvalues},\n  author={Rump, Siegfried M},\n  journal={Linear algebra and its applications},\n  volume={324},\n  number={1-3},\n  pages={209--226},\n  year={2001},\n  publisher={Elsevier}\n}\n\n</details></li></ul>\n\n","category":"section"},{"location":"references/#[RUM99]","page":"References","title":"[RUM99]","text":"<ul><li>\n\nRump, Siegfried M. Fast and parallel interval arithmetic, BIT Numerical Mathematics 39.3, 534-554, 1999\n\n<li style=\"list-style: none\"><details>\n<summary>bibtex</summary>\n\n@article{rump1999fast,\n  title={Fast and parallel interval arithmetic},\n  author={Rump, Siegfried M},\n  journal={BIT Numerical Mathematics},\n  volume={39},\n  number={3},\n  pages={534--554},\n  year={1999},\n  publisher={Springer}\n}\n\n</details></li></ul>\n\n","category":"section"},{"location":"references/#[SKA06]","page":"References","title":"[SKA06]","text":"<ul><li>\n\nSkalna, Iwona A Method for Outer Interval Solution of Systems of Linear Equations Depending Linearly on Interval Parameters, Reliable Computing, 12.2, 107-120, 2006\n\n<li style=\"list-style: none\"><details>\n<summary>bibtex</summary>\n\n@article{skalna2006,\n  title={A Method for Outer Interval Solution of Systems of Linear Equations Depending Linearly on Interval Parameters},\n  author={Skalna, Iwona},\n  journal={Reliable Computing},\n  volume={12},\n  number={2},\n  pages={107--120},\n  year={2006},\n  publisher={Springer}\n}\n\n</details></li></ul>","category":"section"},{"location":"api/eigenvalues/#Eigenvalues-computations","page":"Eigenvalues","title":"Eigenvalues computations","text":"Pages = [\"eigenvalues.md\"]","category":"section"},{"location":"api/eigenvalues/#Interval-matrices-eigenvalues","page":"Eigenvalues","title":"Interval matrices eigenvalues","text":"","category":"section"},{"location":"api/eigenvalues/#Floating-point-eigenvalues-verification","page":"Eigenvalues","title":"Floating point eigenvalues verification","text":"","category":"section"},{"location":"api/eigenvalues/#IntervalLinearAlgebra.eigenbox-Union{Tuple{T}, Tuple{Symmetric{Interval{T}, Array{Interval{T}, 2}}, Rohn}} where T","page":"Eigenvalues","title":"IntervalLinearAlgebra.eigenbox","text":"eigenbox(A[, method=Rohn()])\n\nReturns an enclosure of all the eigenvalues of A. If A is symmetric, then the output is a real interval, otherwise it is a complex interval.\n\nInput\n\nA – square interval matrix\nmethod – method used to solve the symmetric interval eigenvalue problem (bounding   eigenvalues of general matrices is also reduced to the symmetric case).   Possible values are\n- `Rohn` -- (default) fast method to compute an enclosure of the eigenvalues of\n      a symmetric interval matrix\n- `Hertz` -- finds the exact hull of the eigenvalues of a symmetric interval\n      matrix, but has exponential complexity.\n\nAlgorithm\n\nThe algorithms used by the function are described in [HLA13].\n\nNotes\n\nThe enclosure is not rigorous, meaning that the real eigenvalue problems solved internally utilize normal floating point computations.\n\nExamples\n\njulia> A = [0 -1 -1; 2 -1.399.. -0.001 0; 1 0.5 -1]\n3×3 Matrix{Interval{Float64}}:\n [0, 0]  [-1, -1]                       [-1, -1]\n [2, 2]       [-1.39901, -0.000999999]    [0, 0]\n [1, 1]        [0.5, 0.5]               [-1, -1]\n\njulia> eigenbox(A)\n[-1.90679, 0.970154] + [-2.51903, 2.51903]im\n\njulia> eigenbox(A, Hertz())\n[-1.64732, 0.520456] + [-2.1112, 2.1112]im\n\n\n\n\n\n","category":"method"},{"location":"api/eigenvalues/#IntervalLinearAlgebra.bound_perron_frobenius_eigenvalue-Union{Tuple{AbstractMatrix{T}}, Tuple{T}, Tuple{AbstractMatrix{T}, Any}} where T<:Real","page":"Eigenvalues","title":"IntervalLinearAlgebra.bound_perron_frobenius_eigenvalue","text":"bound_perron_frobenius_eigenvalue(A, max_iter=10)\n\nFinds an upper bound for the Perron-Frobenius eigenvalue of the non-negative matrix A.\n\nInput\n\nA – square real non-negative matrix\nmax_iter – maximum number of iterations of the power method used internally to compute   an initial approximation of the Perron-Frobenius eigenvector\n\nExample\n\njulia> A = [1 2;3 4]\n2×2 Matrix{Int64}:\n 1  2\n 3  4\n\njulia> bound_perron_frobenius_eigenvalue(A)\n5.372281323275249\n\n\n\n\n\n","category":"method"},{"location":"api/eigenvalues/#IntervalLinearAlgebra.verify_eigen-Tuple{Any}","page":"Eigenvalues","title":"IntervalLinearAlgebra.verify_eigen","text":"verify_eigen(A[, λ, X0]; w=0.1, ϵ=1e-16, maxiter=10)\n\nFinds a rigorous bound for the eigenvalues and eigenvectors of A. Eigenvalues are treated as simple.\n\nInput\n\nA       – matrix\nλ       – (optional) approximate value for an eigenvalue of A\nX0      – (optional) eigenvector associated to λ\nw       – relative inflation parameter\nϵ       – absolute inflation parameter\nmaxiter – maximum number of iterations\n\nOutput\n\nInterval bounds on eigenvalues and eigenvectors.\nA boolean certificate (or a vector of booleans if all eigenvalues are computed) cert. If cert[i]==true, then the bounds for the ith eigenvalue and eigenvectore are rigorous, otherwise not.\n\nAlgorithm\n\nThe algorithm for this function is described in [RUM01].\n\nExample\n\njulia> A = Symmetric([1 2;2 3])\n2×2 Symmetric{Int64, Matrix{Int64}}:\n 1  2\n 2  3\n\njulia> evals, evecs, cert = verify_eigen(A);\n\njulia> evals\n2-element Vector{Interval{Float64}}:\n [-0.236068, -0.236067]\n  [4.23606, 4.23607]\n\njulia> evecs\n2×2 Matrix{Interval{Float64}}:\n [-0.850651, -0.85065]  [0.525731, 0.525732]\n  [0.525731, 0.525732]  [0.85065, 0.850651]\n\njulia> cert\n2-element Vector{Bool}:\n 1\n 1\n\n\n\n\n\n","category":"method"},{"location":"api/precondition/#Preconditioners","page":"Preconditioners","title":"Preconditioners","text":"Pages = [\"precondition.md\"]","category":"section"},{"location":"api/precondition/#IntervalLinearAlgebra.AbstractPrecondition","page":"Preconditioners","title":"IntervalLinearAlgebra.AbstractPrecondition","text":"AbstractPrecondition\n\nAbstract type for preconditioners of interval linear systems.\n\n\n\n\n\n","category":"type"},{"location":"api/precondition/#IntervalLinearAlgebra.InverseDiagonalMidpoint","page":"Preconditioners","title":"IntervalLinearAlgebra.InverseDiagonalMidpoint","text":"InverseDiagonalMidpoint <: AbstractPrecondition\n\nPreconditioner that preconditions the linear system Ax=b with the diagonal matrix of A_c^-1, where A_c is the midpoint matrix of A.\n\nNotes\n\nAn object of type InverseDiagonalMidpoint is a function with method\n  (idmp::InverseDiagonalMidpoint)(A::AbstractMatrix{T},\n                                  b::AbstractVector{T}) where {T<:Interval}\n\nExample\n\njulia> A = [2..4 -2..1; -1..2 2..4]\n2×2 Matrix{Interval{Float64}}:\n  [2, 4]  [-2, 1]\n [-1, 2]   [2, 4]\n\njulia> b = [-2..2, -2..2]\n2-element Vector{Interval{Float64}}:\n [-2, 2]\n [-2, 2]\n\njulia> idmp = InverseDiagonalMidpoint()\nInverseDiagonalMidpoint()\n\njulia> idmp(A, b)\n(Interval{Float64}[[0.666666, 1.33334] [-0.666667, 0.333334]; [-0.333334, 0.666667] [0.666666, 1.33334]], Interval{Float64}[[-0.666667, 0.666667], [-0.666667, 0.666667]])\n\n\n\n\n\n","category":"type"},{"location":"api/precondition/#IntervalLinearAlgebra.InverseMidpoint","page":"Preconditioners","title":"IntervalLinearAlgebra.InverseMidpoint","text":"InverseMidpoint <: AbstractPrecondition\n\nPreconditioner that preconditions the linear system Ax=b with A_c^-1, where A_c is the midpoint matrix of A.\n\nNotes\n\nAn object of type InverseMidpoint is a function with method\n  (imp::InverseMidpoint)(A::AbstractMatrix{T},\n                         b::AbstractVector{T}) where {T<:Interval}\n\nExamples\n\njulia> A = [2..4 -2..1; -1..2 2..4]\n2×2 Matrix{Interval{Float64}}:\n  [2, 4]  [-2, 1]\n [-1, 2]   [2, 4]\n\njulia> b = [-2..2, -2..2]\n2-element Vector{Interval{Float64}}:\n [-2, 2]\n [-2, 2]\n\njulia> imp = InverseMidpoint()\nInverseMidpoint()\n\njulia> imp(A, b)\n(Interval{Float64}[[0.594594, 1.40541] [-0.540541, 0.540541]; [-0.540541, 0.540541] [0.594594, 1.40541]], Interval{Float64}[[-0.756757, 0.756757], [-0.756757, 0.756757]])\n\n\n\n\n\n","category":"type"},{"location":"api/precondition/#IntervalLinearAlgebra.NoPrecondition","page":"Preconditioners","title":"IntervalLinearAlgebra.NoPrecondition","text":"NoPrecondition <: AbstractPrecondition\n\nType of the trivial preconditioner which does nothing.\n\nNotes\n\nAn object of type NoPrecondition is a function with method\n  (np::NoPrecondition)(A::AbstractMatrix{T},\n                       b::AbstractVector{T}) where {T<:Interval}\n\nExample\n\njulia> A = [2..4 -2..1; -1..2 2..4]\n2×2 Matrix{Interval{Float64}}:\n  [2, 4]  [-2, 1]\n [-1, 2]   [2, 4]\n\njulia> b = [-2..2, -2..2]\n2-element Vector{Interval{Float64}}:\n [-2, 2]\n [-2, 2]\n\njulia> np = NoPrecondition()\nNoPrecondition()\n\njulia> np(A, b)\n(Interval{Float64}[[2, 4] [-2, 1]; [-1, 2] [2, 4]], Interval{Float64}[[-2, 2], [-2, 2]])\n\n\n\n\n\n","category":"type"},{"location":"applications/FEM_example/#Application-of-Interval-Linear-Algebra-to-FEM-analysis","page":"Interval FEM","title":"Application of Interval Linear Algebra to FEM analysis","text":"The Finite Element Method is widely used to solve PDEs in Engineering applications and particularly in Structural Analysis problems [BAT14]. The procedure consists in discretizing the domain into elements and constructing (assembling) a system of balance equations. For linear problems, this system can be usually written as\n\nK cdot d = f\nqquad\nK = sum_e=1^n_e K_e\n\nwhere n_e is the number of elements of the domain, f is the vector of external loads, K_e is the stiffness matrix of element e in global coordinates, K is the assembled stiffness matrix and d is the vector of unknown displacements. This tutorial shows how IntervalLinearAlgebra can be used to solve structural mechanics problems with uncertainty in the parameters. Particularly, it highlights the importance of parametric interval linear systems.","category":"section"},{"location":"applications/FEM_example/#Simple-truss-structure","page":"Interval FEM","title":"Simple truss structure","text":"A frequent and simple type of structures are Truss structures, which are formed by bars connected but not welded. Truss models are usually considered during the conceptual design of bridges or other structures.","category":"section"},{"location":"applications/FEM_example/#Stiffness-equations","page":"Interval FEM","title":"Stiffness equations","text":"The stiffness matrix of a truss element in the local coordinate system is given by\n\nK_L = s\nleft(\n beginmatrix\n 1  0  -1  0 \n 0  0   0  0 \n-1  0   1  0 \n 0  0   0  0\nendmatrix\nright)\n\nwhere s =fracE AL is the stiffness, E is the Young modulus, A is the area of the cross-section and L is the length of that truss element.\n\nThe change-of-basis matrix is given by\n\n_G(Q)_L = Q =\nleft(\n  beginmatrix\ncos(alpha)  -sin(alpha)  0  0 \n sin(alpha)  cos(alpha)   0  0 \n 0  0   cos(alpha)  -sin(alpha) \n 0  0   sin(alpha)  cos(alpha)\nendmatrix\nright)\n\nThe system of equations for each element is written in local coordinates as\n\nK_L d_L = f_L\n\nand using the change-of-basis we obtain the equations for that element in the global systems of coordinates\n\nK_G d_G = f_G qquad K_G = Q K_L Q^T\n\nAfter the system of equations for each element is in global coordinates, the whole system is assembled.\n\nThe unitary stiffness matrix (for s=1) can be computed using the following function.\n\nfunction unitaryStiffnessMatrix( coordFirstNode, coordSecondNode  )\n  diff      = (coordSecondNode - coordFirstNode)\n  length   = sqrt( diff' * diff )\n  c        = diff[1] / length\n  s        = diff[2] / length\n  Qloc2glo = [ c -s 0 0 ; s c 0 0 ; 0 0 c -s ; 0 0 s c ]\n  Kloc     = [ 1 0 -1 0 ; 0 0 0 0 ; -1 0 1 0 ; 0 0 0 0 ]\n  Kglo     = Qloc2glo * Kloc * transpose(Qloc2glo)\n  return     Kglo, length\nend","category":"section"},{"location":"applications/FEM_example/#Example-problem","page":"Interval FEM","title":"Example problem","text":"A problem based on Example 4.1 from [SKA06] is considered. The following diagram shows the truss structure considered.\n\n<img src=\"../../assets/trussDiagram.svg\" style=\"width: 100%\" alt=\"truss diagram\"/>","category":"section"},{"location":"applications/FEM_example/#Case-with-fixed-parameters","page":"Interval FEM","title":"Case with fixed parameters","text":"The scalar parameters considered are given by\n\nE = 2e11 ; # Young modulus\nA = 5e-3 ; # Cross-section area\nnothing #hide\n\nThe coordinate matrix is given by\n\nnodesCMatrix = [ 0.0 0.0 ;\n                 1.0 1.0 ;\n                 2.0 0.0 ;\n                 3.0 1.0 ;\n                 4.0 0.0 ];\nnothing #hide\n\nthe connectivity matrix is given by\n\nconnecMatrix = [ 1     2 ;\n                 1     3 ;\n                 2     3 ;\n                 2     4 ;\n                 3     4 ;\n                 3     5 ;\n                 4     5 ];\nnothing #hide\n\nand the fixed degrees of freedom (supports) are defined by the vector\n\nfixedDofs = [ 2 9 10 ];\nnothing #hide\n\nThe number of elements and nodes are computed, as well as the free degrees of freedom.\n\nnumNodes = size( nodesCMatrix )[1]  # compute the number of nodes\nnumElems = size( connecMatrix )[1]  # compute the number of elements\nfreeDofs = zeros(Int8, 2*numNodes-length(fixedDofs))\nindDof  = 1 ; counter = 0\nwhile indDof <= (2*numNodes)\n  if !(indDof in fixedDofs)\n    global counter = counter + 1\n    freeDofs[ counter ] = indDof\n  end\n  global indDof = indDof + 1\nend\n\nThe global stiffness equations are computed for the unknown displacements (free dofs)\n\nKG = zeros( 2*numNodes, 2*numNodes )\nFG = zeros( 2*numNodes )\nfor elem in 1:numElems\n  indexFirstNode  = connecMatrix[ elem, 1 ]\n  indexSecondNode = connecMatrix[ elem, 2 ]\n  dofsElem = [2*indexFirstNode-1 2*indexFirstNode 2*indexSecondNode-1 2*indexSecondNode ]\n  KGelem, lengthElem = unitaryStiffnessMatrix( nodesCMatrix[ indexSecondNode, : ], nodesCMatrix[ indexFirstNode, : ] )\n  stiffnessParam = E * A / lengthElem\n  for i in 1:4\n    for j in 1:4\n      KG[ dofsElem[i], dofsElem[j] ] = KG[ dofsElem[i], dofsElem[j] ] + stiffnessParam * KGelem[i,j]\n    end\n  end\nend\nFG[4] = -1e4 ;\nKG = KG[ freeDofs, : ]\nKG = KG[ :, freeDofs ]\nFG = FG[ freeDofs ]\n\nand the system is solved.\n\nu = KG \\ FG\nUG = zeros( 2*numNodes )\nUG[ freeDofs ] = u\n\nThe reference (dashed blue line) and deformed (solid red) configurations of the structure are ploted. Since the displacements are very small, a scaleFactor is considered to amplify the deformation and ease the visualization.\n\nusing Plots\nscaleFactor = 2e3\nplot();\nfor elem in 1:numElems\n  indexFirstNode  = connecMatrix[ elem, 1 ];\n  indexSecondNode = connecMatrix[ elem, 2 ];\n  # plot reference element\n  plot!( nodesCMatrix[ [indexFirstNode, indexSecondNode], 1 ],\n         nodesCMatrix[ [indexFirstNode, indexSecondNode], 2 ],\n         linestyle = :dash,  aspect_ratio = :equal,\n         linecolor = \"blue\", legend = false)\n\n  # plot deformed element\n  plot!( nodesCMatrix[ [indexFirstNode, indexSecondNode], 1 ]\n           + scaleFactor* [ UG[indexFirstNode*2-1], UG[indexSecondNode*2-1]] ,\n         nodesCMatrix[ [indexFirstNode, indexSecondNode], 2 ]\n           + scaleFactor* [ UG[indexFirstNode*2  ], UG[indexSecondNode*2  ]] , markershape = :circle, aspect_ratio = :equal, linecolor = \"red\",\n           linewidth=1.5, legend = false )\nend\nxlabel!(\"x (m)\") # hide\nylabel!(\"y (m)\") # hide\ntitle!( \"Deformed with scale factor \" * string(scaleFactor) ) # hide\nsavefig(\"deformed.png\") # hide\n\n(Image: )","category":"section"},{"location":"applications/FEM_example/#Problem-with-interval-parameters","page":"Interval FEM","title":"Problem with interval parameters","text":"Suppose now we have a 10% uncertainty for the stiffness s_23 associated with the third element. To model the problem, we introduce the symbolic variable s23 using the IntervalLinearAlgebra macro @affinevars.\n\nusing IntervalLinearAlgebra\n@affinevars s23\n\nnow we can construct the matrix as before\n\nKGp = zeros(AffineExpression{Float64}, 2*numNodes, 2*numNodes );\nfor elem in 1:numElems\n  print(\" assembling stiffness matrix of element \", elem , \"\\n\")\n  indexFirstNode  = connecMatrix[ elem, 1 ]\n  indexSecondNode = connecMatrix[ elem, 2 ]\n  dofsElem = [2*indexFirstNode-1 2*indexFirstNode 2*indexSecondNode-1 2*indexSecondNode ]\n  KGelem, lengthElem = unitaryStiffnessMatrix( nodesCMatrix[ indexSecondNode, : ], nodesCMatrix[ indexFirstNode, : ] )\n  if elem == 3\n    stiffnessParam = s23\n  else\n    stiffnessParam = E * A / lengthElem\n  end\n  for i in 1:4\n    for j in 1:4\n      KGp[ dofsElem[i], dofsElem[j] ] = KGp[ dofsElem[i], dofsElem[j] ] + stiffnessParam * KGelem[i,j]\n    end\n  end\nend\nKGp = KGp[ freeDofs, : ]\nKGp = KGp[ :, freeDofs ]\n\nNow we can construct the AffineParametricArray\n\nKGp = AffineParametricArray(KGp)\n\nThe range of the stiffness is\n\nsrange = E * A / sqrt(2) ± 0.1 * E * A / sqrt(2)\n\nTo solve the system, we could of course just subsitute srange into the parametric matrix KGp and solve the \"normal\" interval linear system (naive approach)\n\nusimple = solve(KGp(srange), Interval.(FG))\n\nThis approach, however suffers from the dependency problem and hence the computed displacements will be an overestimation of the true displacements.\n\nTo mitigate this issue, algorithms to solve linear systems with parameters have been developed. In this case we use the algorithm presented in [SKA06]\n\nuparam = solve(KGp, FG, srange)\n\nWe can now compare the naive and parametric solution\n\nhcat(usimple, uparam)/1e-6\n\nAs you can see, the naive non-parametric approach significantly overestimates the displacements. It is true that for this very simple and small structure, both displacements are small, however as the number of nodes increases, the effect of the dependency problem also increases and the non-parametric approach will fail to give useful results. This is demonstrated in the next section.","category":"section"},{"location":"applications/FEM_example/#A-continuum-mechanics-problem","page":"Interval FEM","title":"A continuum mechanics problem","text":"In this problem a simple solid plane problem is considered. The solid is fixed on its bottom edge and loaded with a shear tension on the top edge.\n\nFirst, we set the geometry and construct a regular grid of points\n\nL   = [1.0, 4.0]         # dimension in each direction\nt   = 0.2                # thickness\nnx  = 10                 # number of divisions in direction x\nny  = 20                 # number of divisions in direction y\nnel = [nx, ny]\nneltot = 2 * nx * ny;    # total number of elements\nnnos         = nel .+ 1       # number of nodes in each direction\nnnosx, nnosy = nnos\nnnostot      = nnosx * nnosy ;  # total number of nodes\nnothing #hide\n\nwe compute the vector of indexes of the loaded nodes (bottom ones)\n\nstartloadnode = (nnosy - 1) * nnosx + 1 # boundary conditions\nendinloadnode = nnosx * nnosy\nLoadNodes = startloadnode:endinloadnode\nlins1   = range(0, L[1], length=nnosx)\nlins2   = range(0, L[2], length=nnosy)\n\nand construct the matrix of coordinates of the nodes\n\nnodes = zeros(nnostot, 2) # nodes: first column x-coord, second column y-coord\nfor i = 1:nnosy   # first discretize along y-coord\n    idx = (nnosx * (i-1) + 1) : (nnosx*i)\n    nodes[idx, 1] = lins1\n    nodes[idx, 2] = fill(lins2[i], nnosx)\nend\n\nThe connectivity matrix Mcon is computed, considering 3-node triangular elements\n\nMcon = Matrix{Int64}(undef, neltot, 3); # connectivity matrix\nfor j = 1:ny\n    for i = 1:nx\n        intri1 = 2*(i-1)+1+2*(j-1)*nx\n        intri2 = intri1 + 1\n        Mcon[intri1, :] = [j*nnosx+i,   (j-1)*nnosx+i,  j*nnosx+i+1     ]\n        Mcon[intri2, :] = [j*nnosx+i+1,  (j-1)*nnosx+i,  (j-1)*nnosx+i+1]\n    end\nend\n\nthe undeformed mesh is plotted as follows\n\nXel = Matrix{Float64}(undef, 3, neltot); Yel = Matrix{Float64}(undef, 3, neltot)\nfor i = 1:neltot\n    Xel[:, i] = nodes[Mcon[i, :], 1] # the j-th column has the x value at the j-th element\n    Yel[:, i] = nodes[Mcon[i, :], 2] # the j-th column has the y value at the j-th element\nend\nfig = plot(ratio=1, xlimits=(-1, 3), title=\"Undeformed mesh\", xlabel=\"x\", ylabel=\"y\")\nplot!(fig, [Xel[:, 1]; Xel[1, 1]], [Yel[:, 1]; Yel[1, 1]], linecolor=:blue, linewidth=1.4, label=\"\")\nfor i = 2:neltot\n    plot!(fig, [Xel[:, i]; Xel[1, i]], [Yel[:, i]; Yel[1, i]], linecolor=:blue, linewidth=1.4, label=\"\")\nend\nsavefig(\"undeformed2.png\") # hide\n\n(Image: )\n\nLet us now define the material parameters. Here we assume a 10% uncertainty on the Young modulus, while Poisson ratio and the density are fixed. can be related to a steel plate problem with an unknown composition, thus unknown exact Young modulus value.\n\nν  = 0.25   # Poisson\nρ  = 8e3  # density\n\n@affinevars E # Young modulus, defined as symbolic variable\nEn = 200e9  # nominal value of the young modulus\nErange = En ± 0.1 * En # uncertainty range of the young modulus\n\nWe can now assemble the global stiffness matrix. We set the constitutive matrix for a plane stress state.\n\nC = E / (1-ν^2) * [ 1    ν         0 ;\n                    ν    1         0 ;\n                    0    0   (1-ν)/2 ]\n\nWe compute the free and fixed degrees of freedom\n\nfunction nodes2dofs(u)\n    v = Vector{Int64}(undef, 2*length(u))\n    for i in 1:length(u)\n        v[2i-1] = 2u[i] - 1;   v[2i] = 2u[i]\n    end\n    return v\nend\nFixNodes = 1:nnosx\nFixDofs = nodes2dofs(FixNodes)              # first add all dofs of the nodes\ndeleteat!(FixDofs, 3:2:(length(FixDofs)-2)) # then remove the free dofs of the nodes\nLibDofs = Vector(1:2*nnostot)               # free degrees of fredom\ndeleteat!(LibDofs, FixDofs)\n\nand we assemble the matrix\n\nfunction stiffness_matrix(x, y, C, t)\n\n    A = det([ones(1, 3); x'; y']) / 2 # element area\n    B = 1 / (2*A) * [y[2]-y[3]                  0    y[3]-y[1]             0    y[1]-y[2]           0   ;\n                             0          x[3]-x[2]            0     x[1]-x[3]            0     x[2]-x[1] ;\n                     x[3]-x[2]          y[2]-y[3]    x[1]-x[3]     y[3]-y[1]    x[2]-x[1]     y[1]-y[2] ]\n\n    K = B' * C * B * A * t ;\n    return K\nend\n\nKG = zeros(AffineExpression{Float64}, 2*nnostot, 2*nnostot);\nfor i = 1:neltot\n    Ke = stiffness_matrix(Xel[:, i], Yel[:, i], C, t)\n    aux = nodes2dofs(Mcon[i, :])\n    KG[aux, aux] .+= Ke\nend\n\nK = AffineParametricArray(KG[LibDofs, LibDofs])\n\nFinally, we assemble the loads vector\n\nareaelemsup = L[1] / nx * t\n\nf = zeros(2*nnostot);\n\nf[2*LoadNodes[1]] = 0.5 * areaelemsup;\n\nfor i in 2:(length(LoadNodes)-1)\n    idx = 2 * LoadNodes[i]\n\n    f[idx-1] = 1 * areaelemsup # horizontal force\nend\nf[2*LoadNodes[end]] = 0.5 * areaelemsup\n\nq   = 1e9  # distributed load on the up_edge\nF = q * f;\nFLib = F[LibDofs]\nnothing # hide\n\nnow we can solve the displacements from the parametric interval linear system and plot minimum and maximum displacement.\n\nu = solve(K, FLib, Erange) # solving\n\nplotting\n\nU = zeros(Interval, 2*nnostot)\nU[LibDofs] .= u\n\nUx = U[1:2:2*nnostot-1]\nUy = U[2:2:2*nnostot]\n\nnodesdef = hcat(nodes[:, 1] + Ux, nodes[:, 2] + Uy);\n\nXeld = Interval.(copy(Xel))\nYeld = Interval.(copy(Yel))\n\nbuild elements coordinate vectors\n\nfor i = 1:neltot\n    Xeld[:, i] = nodesdef[Mcon[i, :], 1] #  the j-th column has the x coordinate of the j-th element\n    Yeld[:, i] = nodesdef[Mcon[i, :], 2] #  the j-th column has the y coordinate of the j-th element\nend\n\nplot!(fig, [inf.(Xeld[:, 1]); inf.(Xeld[1, 1])], [inf.(Yeld[:, 1]); inf.(Yeld[1, 1])], linecolor=:green, linewidth=1.4, label=\"\", title=\"Displacements\")\nfor i = 2:neltot\n    plot!(fig, [inf.(Xeld[:, i]); inf.(Xeld[1, i])], [inf.(Yeld[:, i]); inf.(Yeld[1, i])], linecolor=:green, linewidth=1.4, label=\"\")\nend\n\nplot!(fig, [sup.(Xeld[:, 1]); sup.(Xeld[1, 1])], [sup.(Yeld[:, 1]); sup.(Yeld[1, 1])], linecolor=:red, linewidth=1.4, label=\"\", title=\"Displacements\")\nfor i = 2:neltot\n    plot!(fig, [sup.(Xeld[:, i]); sup.(Xeld[1, i])], [sup.(Yeld[:, i]); sup.(Yeld[1, i])], linecolor=:red, linewidth=1.4, label=\"\")\nend\nsavefig(\"displacement2.png\") # hide\n\n(Image: )\n\nIn this case, ignoring the dependency and treating the problem as a \"normal\" interval linear system would fail. The reason for this is that the matrix is not strongly regular, which is a necessary condition for the implemented algorithms to work.\n\nis_strongly_regular(K(Erange))","category":"section"},{"location":"applications/FEM_example/#Conclusions","page":"Interval FEM","title":"Conclusions","text":"This tutorial showed how interval methods can be useful in engineering applications dealing with uncertainty. As in most applications the elements in the matrix will depend on some common parameters, due to the dependency problem neglecting the parametric structure will result in poor results. This highlights the importance of parametric interval methods in engineering applications.","category":"section"},{"location":"explanations/preconditioning/#Preconditioning-interval-linear-systems","page":"Preconditioning","title":"Preconditioning interval linear systems","text":"Pages = [\"preconditioning.md\"]","category":"section"},{"location":"explanations/preconditioning/#Basic-concepts","page":"Preconditioning","title":"Basic concepts","text":"Consider the square interval linear system\n\nmathbfAx=mathbfb\n\npreconditioning the interval linear system by a real matrix C means to multiply both sides of the equation by C, obtaining the new system\n\nCmathbfAx=Cmathbfb\n\nwhich is called preconditioned system. Let us denote by A_c the midpoint matrix of mathbfA. Popular choices for C are\n\nInverse midpoint preconditioning: Capprox A_c^-1\nInverse diagonal midpoint preconditioning: Capprox D_A_c^-1 where D_A_c is the diagonal matrix containing the main diagonal of A_c.","category":"section"},{"location":"explanations/preconditioning/#Advantages-of-preconditioning","page":"Preconditioning","title":"Advantages of preconditioning","text":"Using preconditioning to solve an interval linear system can have mainly two advantages.","category":"section"},{"location":"explanations/preconditioning/#Extend-usability-of-algorithms","page":"Preconditioning","title":"Extend usability of algorithms","text":"Some algorithms require the matrix to have a specific structure in order to be used. For example Hansen-Bliek-Rohn algorithm requires mathbfA to be an H-matrix. However, the algorithm can be extended to work to strongly regular matrices using inverse midpoint preconditioning. (Recall that an interval matrix is strongly regular if A_c^-1mathbfA is an H-matrix).","category":"section"},{"location":"explanations/preconditioning/#Improve-numerical-stability","page":"Preconditioning","title":"Improve numerical stability","text":"Even if the algorithms theoretically work, they can be prone to numerical instability without preconditioning. This is demonstrated with the following example, a more deep theoretical analysis can be found in [NEU90].\n\nLet mathbfA be an interval lower triangular matrix with all 1 1 in the lower part, for example\n\nusing IntervalLinearAlgebra\n\nN = 5 # problem dimension\nA = tril(fill(1..1, N, N))\n\nand let mathbfb having -2 2 as first element and all other elements set to zero\n\nb = vcat(-2..2, fill(0, N-1))\n\nthe \"pen and paper\" solution would be  -2 2 -2 2 0 0 0 0 0 0^mathsfT, that is a vector with -2 2 as first two elements and all other elements set to zero. Now, let us try to solve without preconditioning.\n\nsolve(A, b, GaussianElimination(), NoPrecondition())\n\nsolve(A, b, HansenBliekRohn(), NoPrecondition())\n\nIt can be seen that the width of the intervals grows exponentially, this gets worse with bigger matrices.\n\nN = 100 # problem dimension\nA1 = tril(fill(1..1, N, N))\nb1 = [-2..2, fill(0..0, N-1)...]\n\nsolve(A1, b1, GaussianElimination(), NoPrecondition())\n\nsolve(A1, b1, HansenBliekRohn(), NoPrecondition())\n\nHowever this numerical stability issue is solved using inverse midpoint preconditioning.\n\nsolve(A, b, GaussianElimination(), InverseMidpoint())\n\nsolve(A, b, HansenBliekRohn(), InverseMidpoint())","category":"section"},{"location":"explanations/preconditioning/#Disadvantages-of-preconditioning","page":"Preconditioning","title":"Disadvantages of preconditioning","text":"While preconditioning is useful, sometimes even necessary, to solve interval linear systems, it comes at a price. It is important to understand that the preconditioned interval linear system is not equivalent to the original one, particularly the preconditioned problem can have a larger solution set.\n\nLet us consider the following linear system\n\nA = [2..4 -2..1;-1..2 2..4]\n\nb = [-2..2, -2..2]\n\nNow we plot the solution set of the original and preconditioned problem using Oettli-Präger\n\nusing LazySets, Plots\n\npolytopes = solve(A, b, LinearOettliPrager())\npolytopes_precondition = solve(A, b, LinearOettliPrager(), InverseMidpoint())\n\nplot(UnionSetArray(polytopes_precondition), ratio=1, label=\"preconditioned\", legend=:right)\nplot!(UnionSetArray(polytopes), label=\"original\", α=1)\nxlabel!(\"x\")\nylabel!(\"y\")\nsavefig(\"solution_set_precondition.png\") # hide\n\n(Image: )","category":"section"},{"location":"explanations/preconditioning/#Take-home-lessons","page":"Preconditioning","title":"Take-home lessons","text":"Preconditioning an interval linear system can enlarge the solution set\nPreconditioning is sometimes needed to achieve numerical stability\nA rough rule of thumb (same used by IntervalLinearAlgebra.jl if no preconditioning is specified)\nnot needed for M-matrices and strictly diagonal dominant matrices\nmight be needed for H-matrices (IntervalLinearAlgebra.jl uses inverse midpoint by default with H-matrices)\nmust be used for strongly regular matrices","category":"section"},{"location":"CONTRIBUTING/#IntervalLinearAlgebra.jl-contribution-guidelines","page":"Contributing","title":"IntervalLinearAlgebra.jl contribution guidelines","text":"First of all, huge thanks for your interest in the package! ✨\n\nThis page has some hopefully useful guidelines. If this is your first time contributing, please read the pull request-workflow section, mainly to make sure everything works smoothly and you don't get stuck with some nasty technicalities. \n\nYou are also encouraged to read the coding and documentation guidelines, but you don't need to deeply study and memorize those. Core developers are here to help you. Most importantly, relax and have fun!\n\nThe core developers of the package can be found in the #intervals channel in the Julia slack or zulip, links to join the platforms can be found here","category":"section"},{"location":"CONTRIBUTING/#Opening-issues","page":"Contributing","title":"Opening issues","text":"If you spot something strange in the software (something doesn't work or doesn't behave as expected) do not hesitate to open a bug issue.\n\nIf have an idea of how to make the package better (a new feature, a new piece of documentation, an idea to improve some existing feature), you can open an enhancement issue. \n\nIn both cases, try to follow the template, but do not worry if you don't know how to fill something. \n\nIf you feel like your issue does not fit any of the above mentioned templates (e.g. you just want to ask something), you can also open a blank issue.","category":"section"},{"location":"CONTRIBUTING/#Pull-request-workflow","page":"Contributing","title":"Pull request workflow","text":"Pull requests are also warmly welcome. For small fixes/additions, feel free to directly open a PR. For bigger more ambitious PRs, it is preferable to open an issue first to discuss it. As a rule of thumb, every pull request should be as atomic as possible (fix one bug, add one feature, address one issue).","category":"section"},{"location":"CONTRIBUTING/#Setup","page":"Contributing","title":"Setup","text":"note: Note\nThis is just one way, you can do differently (e.g. clone your fork and add the original repo as upstream). In that case, make sure to use the correct remote names\n\nThis is something that needs to be done only once, the first time you start contributing\n\n1. From the Julia REPL in package mode (you can enter package mode by typing ]) do\n\npkg> dev IntervalLinearAlgebra\n\nthis will clone the repository into .julia/dev/IntervalLinearAlgebra. When you dev the package, Julia will use the code in the dev folder instead of the official released one. If you want to go back to use the released version, you can do free IntervalLinearAlgebra.\n\n2. Fork the repository.\n\n3. Navigate to .julia/dev/IntervalLinearAlgebra where you cloned the original repository before. Now you need to add your fork as remote. This can be done with\n\ngit remote add $your_remote_name $your_fork_url\n\nyour_remote_name can be whatever you want. your_fork_url is the url you would use to clone your fork repository. For example if your github username is lucaferranti and you want to call the remote lucaferranti then the previous command would be\n\ngit remote add lucaferranti https://github.com/lucaferranti/IntervalLinearAlgebra.jl.git\n\nyou can verify that you have the correct remotes with git remote -v the output should be similar to\n\nlucaferranti  https://github.com/lucaferranti/IntervalLinearAlgebra.jl.git (fetch)\nlucaferranti  https://github.com/lucaferranti/IntervalLinearAlgebra.jl.git (push)\norigin        https://github.com/JuliaIntervals/IntervalLinearAlgebra.jl.git (fetch)\norigin        https://github.com/JuliaIntervals/IntervalLinearAlgebra.jl.git (push)\n\nNow everything is set!","category":"section"},{"location":"CONTRIBUTING/#Contribution-workflow","page":"Contributing","title":"Contribution workflow","text":"0. Navigate to .julia/dev/IntervalLinearAlgebra and make sure you are on the main branch. You can check with git branch and if needed use git switch main to switch to the main branch. The next steps assume you are in the IntervalLinearAlgebra folder.\n\n1. Before you start modifying, it's good to make sure that your local main branch is synchronized with the main branch in the package repo. To do so, run\n\ngit fetch origin\ngit merge origin/main\n\nSince you should never directly modify the main branch locally, this should not cause any conflicts. If you didn't follow the previous setup instructions, you may need to change origin with the appropriate remote name.\n\n2. Now create a new branch for the new feature you want to develop. If possible, the branch should start with your name/initials and have a short but descriptive name of what you are doing (no strict rules). For example, if I (Luca Ferranti) want to fix the code that computes the eigenvalues of a symmetric matrix, I would call the branch lf-symmetric-eigvals or something like that. You can create a new branch and switch to it with\n\ngit switch -c lf-symmetric-eigvals\n\nIf you are targetting a specific issue, you can also name the branch after the issue number, e.g. lf-42.\n\n3. Now let the fun begin! Fix bugs, add the new features, modify the docs, whatever you do, it's gonna be awesome! Check also the coding guidelines and documentation guidelines. Do not worry if it feels like a lot of rules, the core developers are here to help and guide.\n\n4. It is important to run the tests of the package locally, to check that you haven't accidentally broken anything. You can run the tests with\n\njulia --project test/runtests.jl\n\nIf you have changed the documentation, you can build it locally with\n\njulia --project=docs docs/make.jl\n\nThis will build the docs in the docs/build folder, you can open docs/build/index.html and check that everything looks nice. Check also in the terminal that you don't have error messages (no broken links, doctests pass).\n\n5. When you are ready, commit your changes. If example you want to commit src/file1.jl, src/file2.jl\n\ngit add src/file1.jl src/file2.jl\ngit commit -m \"short description of what you did\"\n\nYou can also add and commit all changes at once with\n\ngit commit -a -m \"short description of what you did\"\n\nfinally you are ready to push to your fork. If your fork remote is called lucaferranti and your branch is called lf-symmetric-eigvals, do\n\ngit push -u lucaferranti lf-symmetric-eigvals\n\nThe -u flag sets the upstream, so next time you want to push to the same branch you can just do git push.\n\n6. Next, go to the package repository, you should see a message inviting you to open a pull request, do it! Make sure you are opening the PR to origin/main. Try to fill the blanks in the pull request template, but do not worry if you don't know anything. Also, your work needs not be polished and perfect to open the pull request! You are also very welcome to open it as a draft and request feedback, assistance, etc.\n\n7. If nothing happens within 7 working days feel free to ping Luca Ferranti (@lucaferranti) every 1-2 days until you get his attention.","category":"section"},{"location":"CONTRIBUTING/#Coding-guideline","page":"Contributing","title":"Coding guideline","text":"Try to roughly follow the bluestyle style guideline.\nIf you add new functionalities, they should also be tested. Exported functions should also have a docstring.\nThe test folder should roughly follow the structure of the src folder. That is if you create src/file1.jl there should also be test/test_file1.jl. There can be exceptions, the main point being that both test and src should have a logical structure and should be easy to find the tests for a given function.\nThe runtests.jl should have only inlcude statements.","category":"section"},{"location":"CONTRIBUTING/#Package-version","page":"Contributing","title":"Package version","text":"Generally, if the pull request changes the source code, a new version of the package should be released. This means, that if you change the source code, you should also update the version entry in the Project.toml. Since the package is below version 1, the version update rules are\n\nupdate minor version for breaking changes, e.g. 0.3.5  => 0.4.0\nupdate patch version for non breaking changes, e.g. 0.3.5 => 0.3.6\nIt is perfectly fine that you are not sure how to update the version. Just mention in the PR and you will receive guidance\nThe person who merges the PR also register the new version.","category":"section"},{"location":"CONTRIBUTING/#Add-dependency","page":"Contributing","title":"Add dependency","text":"If the function you are adding needs an external package (say Example.jl), this should be added as dependency, to do so\n\nGo to IntervalLinearAlgebra.jl and start a Julia session and activate the current environment with julia --project\nEnter the package mode (press ]) and add the package you want to add, e.g ]add Example.\nYou can verify that the package was added by typing st while in package mode. You can exit the package mode by pressing backspace\nOpen the Project.toml file, your package should now be listed in the [deps] section.\nIn the [compat] section, specify the compatibility requirements. Packages are listed alphabetically. More details about specifying compatibility can be found here\nIn the IntervalLinearAlgebra.jl file, add the line using Example together with the other using statements, or import Example: fun1, fun2 if you are planning to extend those functions.\n\nIf the dependency is quite heavy and used only by some functionalities, you may consider adding that as optional dependency. To do so,\n\nRepeat the steps 1-5 above\nIn the [deps] section of Project.toml locate the package you want to make an optional dependency and move the corresponding line to [extras], keep alphabetical ordering.\nAdd the dependency name to the test entry in the [targets] section\nIn the IntervalLinearAlgebra.jl file, locate the __init__ function and add the line\n\n@require \"\"\"Example = \"7876af07-990d-54b4-ab0e-23690620f79a\" include(\"file.jl\")\"\"\"\n\nwhere file.jl is the file containing the functions needing Example.jl. The line Example = \"7876af07-990d-54b4-ab0e-23690620f79a\" is the same in the Project.toml\n\nIn file.jl the first line should be using .Example (or import .Example: fun1, fun2), note the dot before the package name. Then write the functions in the file normally","category":"section"},{"location":"CONTRIBUTING/#Documentation-guideline","page":"Contributing","title":"Documentation guideline","text":"Documentation is written with Documenter.jl. Documentation files are in docs/src, generally as markdown file.\nIf you want to modify an existing file, open it and start writing. If you want to add a new page, create a new markdown file in the appropriate subfolder of docs/src and add the line \"mytitle\" => \"path/to/file.md\" to the page structure in the docs/make.jl file here. \nIf you want to include a Julia code example that is not executed in the markdown file, use ```julia blocks, e.g.\n\n```julia\na = 1\nb = 2\n```\n\nJulia code that is executed should use ```@example blocks, e.g.\n\n```@example\na = 1\nb = 2\n```\n\nIf you want to reuse variables between @example blocks, they should be named, for example\n\n```@example filename\na = 1\nb = 2\n```\n\n... some text ...\n\n```@example filename\nc = a + b\n```\n\nIf you want to run a Julia code block but don't want the output to be displayed, add nothing # hide as last line of the code block.\nYou can plot and include figures as follows\n\n```@example\n# code for plotting\nsavefig(\"figname.png\") # hide\n```\n\n![][figname.png]\n\nUse single ticks for inline code `A` and double ticks for maths ``A``. For single line equations, use \nFor single-line equations, use ```math blocks, e.g.\n\n```math\n|A_cx-b_c| \\le A_\\Delta|x| + b_\\Delta,\n```\n\nYou can refer to functions in the pacakge with [`func_name`](@ref)\nYou can quote references with [[REF01]](@ref)\nIf you want to add references, you can use the following template\n\n#### [REF01] \n\n```@raw html\n<ul><li>\n```\nAuthor(s), [*Paper name in italic*](link_to_pdf_if_available), other infos (publisher, year, etc.)\n```@raw html\n<li style=\"list-style: none\"><details>\n<summary>bibtex</summary>\n```\n```\nINSERT BIBTEX HERE\n```\n```@raw html\n</details></li></ul>\n```\n---\n\nIf the pdf of the paper is freely (and legally!) available online, make the title of the paper a link to it.\nThe reference code should be first 3 letters of first author surname + last two digits of year, e.g [FER87]. To disambiguate duplicates, use letter, e.g. [FER87a], [FER87b].","category":"section"},{"location":"CONTRIBUTING/#Docstrings","page":"Contributing","title":"Docstrings","text":"Each exported function should have a docstring. The docstring should roughly follow the following structure\n\n\"\"\"\n    funname(param1, param2[, optional_param])\n\nA short description (1-2 lines) of what the function does\n\n### Input\n\nLis of inputs. Not needed if clear from description and signature.\n\n### Output\n\nList of outputs. Not needed if clear from description and signature.\n\n### Notes\n\nAnything else which is important.\n\n### Algorithm\n\nWhat algorithms the function uses, preferably with references.\n\n### Example\n\nAt least one example, formatted as julia REPL, of what the function does.\nPreferably, as a doctest.\n\"\"\"\n\nOptional parameters in the function signature go around brackets.\nList of inputs and outputs can be omitted if the function has few parameters and they are already clearly explained by the function signature and description.\nExamples should be doctests. Exceptions to this can occur if e.g. the function is not deterministic (random initialization) or requires a heavy optional dependency.\n\nHere is an example\n\n\"\"\"\n    something(A::Matrix{T}, b::Vector{T}[, tol=1e-10]) where {T<:Interval}\n\nthis function computes the somethig product between the interval matrix ``A`` and \ninterval vector ``b``.\n\n### Input\n\n`A`   -- interval matrix\n`b`   -- interval vector\n`tol` -- (optional), tolerance to compute the something product, default 1e-10\n\n### Output\n\nThe interval vector representing the something product.\n\n### Notes\n\nIf `A` and `b` are real, use the [`somethingelse`](@ref) function instead.\n\n### Algorithm\n\nThe function uses the *something sometimes somewhere* algorithm proposed by Someone in [[SOM42]](@ref).\n\n### Example\n\n```jldoctest\njulia> A = [1..2 3..4;5..6 7..8]\n2×2 Matrix{Interval{Float64}}:\n[1, 2]  [3, 4]\n[5, 6]  [7, 8]\n\njulia> b = [-2..2, -2..2]\n2-element Vector{Interval{Float64}}:\n[-2, 2]\n[-2, 2]\n\njulia> something(A, b)\n2-element Vector{Interval{Float64}}:\n[-1, 1]\n[-7, 8]\n```\n\"\"\"","category":"section"},{"location":"CONTRIBUTING/#Acknowledgments","page":"Contributing","title":"Acknowledgments","text":"Here is a list of useful resources from which this guideline was inspired\n\nJuliaReach developers docs\nMaking a first Julia pull request\nColPrac\nJulia contributing guideline","category":"section"},{"location":"tutorials/linear_systems/#Linear-systems","page":"Linear systems","title":"Linear systems","text":"Pages = [\"linear_systems.md\"]\n\nThis tutorial will show you how to solve linear systems rigorously using IntervalLinearAlgebra.jl.","category":"section"},{"location":"tutorials/linear_systems/#Solve-interval-linear-systems","page":"Linear systems","title":"Solve interval linear systems","text":"An interval linear system mathbfAx=mathbfb is a linear system where mathbfA and mathbfb contain intervals. In general, the solution set mathbfx can have a complex non-convex shape and can thus be hard to characterize exactly (see this article for more details). Hence we are interested in finding an interval box containing mathbfx. In IntervalLinearAlgebra.jl, this is achieved through the solve function, which gives a handy interface to choose the algorithm and preconditioning mechanism. The syntax to call solve is \n\nsolve(A, b, method, precondition)\n\nA is an interval matrix\nb is an interval vector\nmethod is an optional parameter to choose the algorithm used to solve the interval linear system, see below for more details\nprecondition is an optional parameter to choose the preconditioning for the problem. More details about preconditoining can be found here","category":"section"},{"location":"tutorials/linear_systems/#Methods","page":"Linear systems","title":"Methods","text":"The supported methods are\n\nDirect solvers\nGaussianElimination\nHansenBliekRohn\nLinearOettliPrager (requires importing LazySets.jl)\nIterative solvers\nLinearKrawczyk\nJacobi\nGaussSeidel\nNonLinearOettliPrager (requires importing IntervalConstraintProgramming.jl)\n\nLinearOettliPrager and NonLinearOettliPrager are \"special\" in the sense that they try to exactly characterize the solution set using Oettli-Präger and are not considered in this tutorial. More information about them can be found here. The other solvers return a vector of intervals, representing an interval enclosure of the solution set. If the method is not specified, Gaussian elimination is used by default.","category":"section"},{"location":"tutorials/linear_systems/#Preconditioning","page":"Linear systems","title":"Preconditioning","text":"The supported preconditioning mechanisms are\n\nNoPrecondition\nInverseMidpoint\nInverseDiagonalMidpoint\n\nIf preconditioning is not specified, then an heuristic strategy based on the type of matrix and solver is used to choose the preconditioning. The strategy is discussed at the end of the preconditioning tutorial.","category":"section"},{"location":"tutorials/linear_systems/#Examples","page":"Linear systems","title":"Examples","text":"We now demonstrate a few examples using the solve function, these examples are taken from [HOR19].\n\nusing IntervalLinearAlgebra\n\nA = [4..6 -1..1 -1..1 -1..1;-1..1 -6.. -4 -1..1 -1..1;-1..1 -1..1 9..11 -1..1;-1..1 -1..1 -1..1 -11.. -9]\n\nb = [-2..4, 1..8, -4..10, 2..12]\n\nsolve(A, b, HansenBliekRohn())\n\nsolve(A, b, GaussianElimination())\n\nsolve(A, b, GaussSeidel())\n\nFor iterative methods, an additional optional parameter X0 representing an initial guess for the solution's enclosure can be given. If not given, a rough initial enclosure is computed using the enclose function.\n\nX0 = fill(-5..5, 4)\nsolve(A, b, GaussSeidel(), InverseMidpoint(), X0)","category":"section"},{"location":"tutorials/linear_systems/#Verify-real-linear-systems","page":"Linear systems","title":"Verify real linear systems","text":"IntervalLinearAlgebra.jl also offers functionalities to solve real linear systems rigorously. It is of course possible to just convert the real system to an interval system and use the methods described above. In this situation, however, the system will have the property where the diameters of the intervals will be very small (zero or a few floating point units). To solve these kind of systems, it can be more efficient to use the epsilon inflation method [RUM10], especially for bigger matrices. Here is an example\n\nA = [1.0 2;3 4]\n\nb = [3, 7]\n\nthe real linear system Ax=b can now be solved rigorously using the epsilon_inflation function.\n\nx, cert = epsilon_inflation(A, b)\n@show cert\nx\n\nThis function returns two values: an interval vector x and a boolean certificate cert. If cert==true then x is guaranteed to be an enclosure of the real linear system Ax=b. If cert == false then the algorithm could not verify that the enclosure is rigorous, i.e. it may or may not contain the true solution.\n\nIn the following example the epsilon inflation method returns a non-rigorous bound\n\nA1 = [1..1+1e-16 2;3 4]\nx1, cert = epsilon_inflation(A1, b)\n@show cert\nx1\n\nSince the matrix A1 is non-regular (it contains the matrix beginbmatrix1234endbmatrix which is singluar), the solution set is unbounded, hence the algorithm could not prove (rightly) that x1 is an enclosure of the true solution. ","category":"section"},{"location":"api/misc/#Miscellaneous","page":"Miscellaneous","title":"Miscellaneous","text":"Other possibly useful functionalities.\n\nPages = [\"misc.md\"]","category":"section"},{"location":"api/misc/#Matrix-multiplication-API","page":"Miscellaneous","title":"Matrix multiplication API","text":"","category":"section"},{"location":"api/misc/#Symbolic-Interface","page":"Miscellaneous","title":"Symbolic Interface","text":"","category":"section"},{"location":"api/misc/#Others","page":"Miscellaneous","title":"Others","text":"","category":"section"},{"location":"api/misc/#IntervalLinearAlgebra.set_multiplication_mode","page":"Miscellaneous","title":"IntervalLinearAlgebra.set_multiplication_mode","text":"set_multiplication_mode(multype)\n\nSets the algorithm used to perform matrix multiplication with interval matrices.\n\nInput\n\nmultype – symbol describing the algorithm used\n:slow – uses traditional matrix multiplication algorithm.\n:rank1 – uses rank1 update\n:fast – computes an enclosure of the matrix product using the midpoint-radius            notation of the matrix [RUM10].\n\nNotes\n\nBy default, :fast is used.\nUsing fast is generally significantly faster, but it may return larger intervals, especially if midpoint and radius have the same order of magnitude   (50% overestimate at most) [RUM99].\n\n\n\n\n\n","category":"function"},{"location":"api/misc/#IntervalLinearAlgebra.@affinevars","page":"Miscellaneous","title":"IntervalLinearAlgebra.@affinevars","text":"@affinevars(x...)\n\nMacro to construct the variables used to represent AffineExpression.\n\nExamples\n\njulia> @affinevars x\n1-element Vector{AffineExpression{Int64}}:\n x\n\njulia> @affinevars x y z\n3-element Vector{AffineExpression{Int64}}:\n x\n y\n z\n\njulia> @affinevars x[1:4]\n4-element Vector{AffineExpression{Int64}}:\n x1\n x2\n x3\n x4\n\n\n\n\n\n","category":"macro"},{"location":"api/misc/#IntervalLinearAlgebra.AffineExpression","page":"Miscellaneous","title":"IntervalLinearAlgebra.AffineExpression","text":"AffineExpression{T}\n\nData structure to represent affine expressions, such as x+2y+z+4.\n\nExamples\n\njulia> @affinevars x y z\n3-element Vector{AffineExpression{Int64}}:\n x\n y\n z\n\njulia> p1 = x + 2y + z + 4\nx+2y+z+4\n\n\n\n\n\n","category":"type"},{"location":"api/misc/#IntervalLinearAlgebra.AffineParametricArray","page":"Miscellaneous","title":"IntervalLinearAlgebra.AffineParametricArray","text":"AffineParametricArray{T, N, MT<:AbstractArray{T, N}}\n\nArray whose elements have an affine dependency on a set of parameteres p₁ p₂  pₙ.\n\nFields\n\ncoeffs::Vector{MT} – vector of arrays, corresponds to the coefficients of each variable.\n\nExample\n\njulia> @affinevars x y z\n3-element Vector{AffineExpression{Int64}}:\n x\n y\n z\n\njulia> A = AffineParametricArray([x+y x-1;x+y+z 1])\n2×2 AffineParametricMatrix{Int64, Matrix{Int64}}:\n x+y    x-1\n x+y+z  1\n\n\n\n\n\n","category":"type"},{"location":"api/misc/#IntervalLinearAlgebra.Orthants","page":"Miscellaneous","title":"IntervalLinearAlgebra.Orthants","text":"Orthants\n\nIterator to go through all the 2ⁿ vectors of length n with elements 1. This is equivalento to going through the orthants of an n-dimensional euclidean space.\n\nFields\n\nn::Int – dimension of the vector space\n\nExample\n\njulia> for or in Orthants(2)\n       @show or\n       end\nor = [1, 1]\nor = [-1, 1]\nor = [1, -1]\nor = [-1, -1]\n\n\n\n\n\n","category":"type"},{"location":"api/misc/#IntervalLinearAlgebra.comparison_matrix-Union{Tuple{StaticArraysCore.SMatrix{N, N, T, M}}, Tuple{T}, Tuple{M}, Tuple{N}} where {N, M, T<:Interval}","page":"Miscellaneous","title":"IntervalLinearAlgebra.comparison_matrix","text":"comparison_matrix(A::AbstractMatrix{T}) where {T<:Interval}\n\nComputes the comparison matrix A of the given interval matrix A according to the definition Aᵢᵢ = mig(Aᵢᵢ) and Aᵢⱼ = -mag(Aᵢⱼ) if ij.\n\nExamples\n\njulia> A = [2..4 -1..1; -1..1 2..4]\n2×2 Matrix{Interval{Float64}}:\n  [2, 4]  [-1, 1]\n [-1, 1]   [2, 4]\n\njulia> comparison_matrix(A)\n2×2 Matrix{Float64}:\n  2.0  -1.0\n -1.0   2.0\n\n\n\n\n\n","category":"method"},{"location":"api/misc/#IntervalLinearAlgebra.enclose-Union{Tuple{T}, Tuple{N}, Tuple{StaticArraysCore.StaticArray{Tuple{N, N}, T, 2}, StaticArraysCore.StaticArray{Tuple{N}, T, 1}}} where {N, T<:Interval}","page":"Miscellaneous","title":"IntervalLinearAlgebra.enclose","text":"enclose(A::AbstractMatrix{T}, b::AbstractVector{T}) where {T<:Interval}\n\nComputes an enclosure of the solution of the interval linear system Ax=b using the algorithm described in sec. 5.7.1 of [HOR19].\n\n\n\n\n\n","category":"method"},{"location":"api/misc/#IntervalLinearAlgebra.interval_isapprox-Tuple{Interval, Interval}","page":"Miscellaneous","title":"IntervalLinearAlgebra.interval_isapprox","text":"interval_isapprox(a::Interval, b::Interval; kwargs)\n\nChecks whether the intervals a and b are approximate equal, that is both their lower and upper bound are approximately equal.\n\nKeywords\n\nSame of Base.isapprox\n\nExample\n\njulia> a = 1..2\n[1, 2]\n\njulia> b = a + 1e-10\n[1, 2.00001]\n\njulia> interval_isapprox(a, b)\ntrue\n\njulia> interval_isapprox(a, b; atol=1e-15)\nfalse\n\n\n\n\n\n","category":"method"},{"location":"api/misc/#IntervalLinearAlgebra.interval_norm-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T<:Interval","page":"Miscellaneous","title":"IntervalLinearAlgebra.interval_norm","text":"interval_norm(A::AbstractMatrix{T}) where {T<:Interval}\n\ncomputes the infinity norm of interval matrix A.\n\nExamples\n\njulia> A = [2..4 -1..1; -1..1 2..4]\n2×2 Matrix{Interval{Float64}}:\n  [2, 4]  [-1, 1]\n [-1, 1]   [2, 4]\n\njulia> interval_norm(A)\n5.0\n\n\n\n\n\n","category":"method"},{"location":"api/misc/#IntervalLinearAlgebra.interval_norm-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T<:Interval","page":"Miscellaneous","title":"IntervalLinearAlgebra.interval_norm","text":"interval_norm(A::AbstractVector{T}) where {T<:Interval}\n\ncomputes the infinity norm of interval vector v.\n\nExamples\n\njulia> b = [-2..2, -3..2]\n2-element Vector{Interval{Float64}}:\n [-2, 2]\n [-3, 2]\n\njulia> interval_norm(b)\n3.0\n\n\n\n\n\n","category":"method"},{"location":"api/misc/#IntervalLinearAlgebra.rref!-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T<:Interval","page":"Miscellaneous","title":"IntervalLinearAlgebra.rref!","text":"rref!(A::AbstractMatrix{T}) where {T<:Interval}\n\nIn-place version of rref.\n\n\n\n\n\n","category":"method"},{"location":"api/misc/#IntervalLinearAlgebra.rref-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T<:Interval","page":"Miscellaneous","title":"IntervalLinearAlgebra.rref","text":"rref(A::AbstractMatrix{T}) where {T<:Interval}\n\nComputes the reduced row echelon form of the interval matrix A using maximum mignitude as pivoting strategy.\n\nExamples\n\njulia> A = [2..4 -1..1; -1..1 2..4]\n2×2 Matrix{Interval{Float64}}:\n  [2, 4]  [-1, 1]\n [-1, 1]   [2, 4]\n\njulia> rref(A)\n2×2 Matrix{Interval{Float64}}:\n [2, 4]  [-1, 1]\n [0, 0]       [1.5, 4.5]\n\n\n\n\n\n","category":"method"},{"location":"api/classify/#Interval-matrices-classification","page":"Interval matrices classification","title":"Interval matrices classification","text":"Pages = [\"classify.md\"]","category":"section"},{"location":"api/classify/#IntervalLinearAlgebra.is_H_matrix-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T<:Interval","page":"Interval matrices classification","title":"IntervalLinearAlgebra.is_H_matrix","text":"is_H_matrix(A::AbstractMatrix{T}) where {T<:Interval}\n\nTests whether the square interval matrix A is an H-matrix, by testing that A^-1e0, where e=1 1  1ᵀ. Note that in practice it tests that a floating point approximation of A^-1e satisfies the condition. For more details see section 4.4 of [HOR19].\n\nExamples\n\njulia> A = [2..4 -1..1; -1..1 2..4]\n2×2 Matrix{Interval{Float64}}:\n  [2, 4]  [-1, 1]\n [-1, 1]   [2, 4]\n\njulia> is_H_matrix(A)\ntrue\n\njulia> A = [2..4 -2..1; -1..2 2..4]\n2×2 Matrix{Interval{Float64}}:\n  [2, 4]  [-2, 1]\n [-1, 2]   [2, 4]\n\njulia> is_H_matrix(A)\nfalse\n\n\n\n\n\n","category":"method"},{"location":"api/classify/#IntervalLinearAlgebra.is_M_matrix-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T<:Interval","page":"Interval matrices classification","title":"IntervalLinearAlgebra.is_M_matrix","text":"is_M_matrix(A::AbstractMatrix{T}) where {T<:Interval}\n\nChecks whether the square interval matrix A is an M-matrix, that is a Z-matrix with non-negative inverse. For more details see section 4.2 of [HOR19].\n\nExamples\n\njulia> A = [2..2 -1..0; -1..0 2..2]\n2×2 Matrix{Interval{Float64}}:\n  [2, 2]  [-1, 0]\n [-1, 0]   [2, 2]\n\njulia> is_M_matrix(A)\ntrue\n\njulia> A = [2..4 -2..1; -1..2 2..4]\n2×2 Matrix{Interval{Float64}}:\n  [2, 4]  [-2, 1]\n [-1, 2]   [2, 4]\n\njulia> is_M_matrix(A)\nfalse\n\n\n\n\n\n","category":"method"},{"location":"api/classify/#IntervalLinearAlgebra.is_Z_matrix-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T<:Interval","page":"Interval matrices classification","title":"IntervalLinearAlgebra.is_Z_matrix","text":"is_Z_matrix(A::AbstractMatrix{T}) where {T<:Interval}\n\nChecks whether the square interval matrix A is a Z-matrix, that is whether Aᵢⱼ0 for all ij. For more details see section 4.2 of [HOR19].\n\nExamples\n\njulia> A = [2..4 -2.. -1; -2.. -1 2..4]\n2×2 Matrix{Interval{Float64}}:\n   [2, 4]  [-2, -1]\n [-2, -1]    [2, 4]\n\njulia> is_Z_matrix(A)\ntrue\n\njulia> A = [2..4 -2..1; -1..2 2..4]\n2×2 Matrix{Interval{Float64}}:\n  [2, 4]  [-2, 1]\n [-1, 2]   [2, 4]\n\njulia> is_Z_matrix(A)\nfalse\n\n\n\n\n\n","category":"method"},{"location":"api/classify/#IntervalLinearAlgebra.is_strictly_diagonally_dominant-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T<:Interval","page":"Interval matrices classification","title":"IntervalLinearAlgebra.is_strictly_diagonally_dominant","text":"is_strictly_diagonally_dominant(A::AbstractMatrix{T}) where {T<:Interval}\n\nChecks whether the square interval matrix A of order n is stictly diagonally dominant, that is if mig(Aᵢᵢ)  _k  i mag(Aᵢₖ) for i=1n. For more details see section 4.5 of [HOR19].\n\nExamples\n\njulia> A = [2..4 -1..1; -1..1 2..4]\n2×2 Matrix{Interval{Float64}}:\n  [2, 4]  [-1, 1]\n [-1, 1]   [2, 4]\n\njulia> is_strictly_diagonally_dominant(A)\ntrue\n\njulia> A = [2..4 -2..1; -1..2 2..4]\n2×2 Matrix{Interval{Float64}}:\n  [2, 4]  [-2, 1]\n [-1, 2]   [2, 4]\n\njulia> is_strictly_diagonally_dominant(A)\nfalse\n\n\n\n\n\n","category":"method"},{"location":"api/classify/#IntervalLinearAlgebra.is_strongly_regular-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T<:Interval","page":"Interval matrices classification","title":"IntervalLinearAlgebra.is_strongly_regular","text":"is_strongly_regular(A::AbstractMatrix{T}) where {T<:Interval}\n\nTests whether the square interval matrix A is strongly regular, i.e. if A_c^-1A is an H-matrix, where A_c is the midpoint matrix of A`. For more details see section 4.6 of [HOR19].\n\nExamples\n\njulia> A = [2..4 -2..1; -1..2 2..4]\n2×2 Matrix{Interval{Float64}}:\n  [2, 4]  [-2, 1]\n [-1, 2]   [2, 4]\n\njulia> is_strongly_regular(A)\ntrue\n\njulia> A = [0..2 1..1;-1.. -1 0..2]\n2×2 Matrix{Interval{Float64}}:\n   [0, 2]  [1, 1]\n [-1, -1]  [0, 2]\n\njulia> is_strongly_regular(A)\nfalse\n\n\n\n\n\n","category":"method"},{"location":"explanations/solution_set/#Solution-set-of-interval-linear-system","page":"Interval system solution set","title":"Solution set of interval linear system","text":"Pages=[\"solution_set.md\"]","category":"section"},{"location":"explanations/solution_set/#Interval-linear-systems","page":"Interval system solution set","title":"Interval linear systems","text":"An interval linear system is defined as\n\nmathbfAmathbfx=mathbfb\n\nwhere mathbfAinmathbbImathbbR^ntimes n and mathbfbinmathbbImathbbR^n are an interval matrix and vector, respectively.\n\nThe solution set  mathbfx is defined as\n\nmathbfx = x in mathbbR^n  Ax=b text for some  AinmathbfA binmathbfb \n\nIn other words, mathbfx is the set of solutions of the real linear systems Ax=b for some  AinmathbfA and binmathbfb. If the interval matrix mathbfA is regular, that is all AinmathbfA are invertible, then the solution set mathbfx will be non-empty and bounded. In general, checking for regularity of an interval matrix has exponential complexity.","category":"section"},{"location":"explanations/solution_set/#Solution-by-Monte-Carlo","page":"Interval system solution set","title":"Solution by Monte-Carlo","text":"A naive approach to solve an interval linear system would be to use Montecarlo, i.e. to randomly sample elements from the intervals and solve the several random real systems. Suppose we want to solve the linear system\n\nbeginbmatrix\n2 4-21\n-1 22 4\nendbmatrixmathbfx =\nbeginbmatrix\n-2 2\n-2 2\nendbmatrix\n\nSince we are planning to solve several thousands of instances of the interval problem and we are working with small arrays, we can use StaticArrays.jl to speed up the computations.\n\nusing IntervalLinearAlgebra, StaticArrays \n\nA = @SMatrix [2..4 -2..1; -1..2 2..4]\nb = @SVector [-2..2, -2..2]\nnothing # hide\n\nTo perform Montecarlo, we need to sample from the intervals. This can be achieved using the rand function, for example \n\nrand(1..2)\n\nwe are now ready for our montecarlo simulation, let us solve 100000 random instances\n\nN = 100000\n\nxs = [rand.(A)\\rand.(b) for _ in 1:N]\nnothing # hide\n\nnow we plot a 2D-histogram to inspect the distribution of the solutions.\n\nusing Plots\n\nx = [xs[i][1] for i in 1:N]\ny = [xs[i][2] for i in 1:N]\n\nhistogram2d(x, y, ratio=1)\nxlabel!(\"x\")\nylabel!(\"y\")\nsavefig(\"histogram-2d.png\") # hide\n\n(Image: )\n\nAs we can see, most of the solutions seem to be condensed close to the origin, but repeating the experiments enough times we also got some solutions farther away, obtaining a star looking area. Now the question is, have we captured the whole solution set?","category":"section"},{"location":"explanations/solution_set/#Oettli-Präger-theorem","page":"Interval system solution set","title":"Oettli-Präger theorem","text":"The solution set mathbfx is exactly characterized by the Oettli-Präger theorem [OET64], which says that an interval linear system mathbfAmathbfx=mathbfb is equivalent to the set of real inequalities\n\nA_cx-b_c le A_Deltax + b_Delta\n\nwhere A_c and A_\\Delta are the midpoint and radius matrix of \\mathbf{A}, b_c and b_Delta are defined similarly. The absolute values are taken elementwise.\n\nWe have now transformed the set of interval equalities into a set of real inequalities. We can easily get rid of the absolute value on the left obtaining the system\n\nbegincases\nA_cx-b_c le A_Deltax + b_Delta\n-(A_cx-b_c) le A_Deltax + b_Delta\nendcases\n\nWe can remove the absolute value on the right by considering each orthant separately, obtaining 2^n linear inequalities, where n is the dimension of the problem.\n\nPractically this means rewriting x=D_ex, where einpm 1^n and D_e is the diagonal matrix with e on the main diagonal. As there are 2^n possible instances of e, we will go through 2^n linear inequalities in the form\n\nbeginbmatrix\nA_c-A_Delta D_e\n-A_c-A_Delta D_e\nendbmatrixxle beginbmatrixb_Delta+b_cb_Delta-b_cendbmatrix\n\nas this inequality is in the form tildeAxle tildeb its solution set will be a convex polytope. This has also an important theoretical consequence: the solution set of any interval linear system is composed by the union of 2^n convex polytopes (some possibly empty), each lying entirely in one orthant.\n\nIn IntervalLinearAlgebra.jl the polytopes composing the solution set can be found using the LinearOettliPrager() solver. Note that to use it you need to import LazySets.jl first.\n\nusing LazySets\n\npolytopes = solve(A, b, LinearOettliPrager())\n\nplot(polytopes, ratio=1, legend=:none)\nhistogram2d!(x, y)\nxlabel!(\"x\")\nylabel!(\"y\")\nsavefig(\"oettli.png\") # hide\n\n(Image: )\n\nAs we can see, the original montecarlo approximation, despite the high number of iterations, could not cover the whole solution set.\n\nNote also that the solution set is non-convex but is composed by 4 convex polygons, one in each orthant. This is a general property of interval linear systems. For example, let us consider the interval linear system\n\nbeginbmatrix\n45 450 20 2\n0 245 450 2\n0 20 2 45 45\nendbmatrixmathbfx=beginbmatrix-1 1\n-1 1\n-1 1endbmatrix\n\nits solution set is depicted in the next picture.\n\n(Image: )","category":"section"},{"location":"explanations/solution_set/#Disadvantages-of-Oettli-Präger","page":"Interval system solution set","title":"Disadvantages of Oettli-Präger","text":"As the number of orthants grows exponential with the dimension n, applying Oettli-Präger has exponential complexity and is thus practically unfeasible in higher dimensions. Moreover, also computing the interval hull of the solution set is NP-hard [ROH95]. For this reason, in practical applications polynomial time algorithms that return an interval enclosure of the solution set are used, although these may return an interval box strictly larger than the interval hull.","category":"section"},{"location":"tutorials/eigenvalues/#Eigenvalue-computations","page":"Eigenvalue computations","title":"Eigenvalue computations","text":"","category":"section"},{"location":"tutorials/eigenvalues/#Eigenvalues-of-interval-matrices","page":"Eigenvalue computations","title":"Eigenvalues of interval matrices","text":"Given a (real or complex) interval matrix AinmathbbIC^ntimes n, we define the eigenvalue set \n\nmathbfLambda=lambdainmathbbC lambdatext is an eigenvalue of Atext for some AinmathbfA\n\nWhile characterizing the solution set mathbfLambda (or even its hull) is computationally challenging, the package offers the function eigenbox which contains an interval box containing mathbfLambda. \n\nnote: Note\nAt the moment, eigenbox is not rigorous, that is the computations for the non-interval eigenvalue problem solved internally are carried out using normal non-verified floating point computations.\n\nTo demonstrate the functionality, let us consider the following interval matrix\n\nusing IntervalLinearAlgebra\n\nA = [-3.. -2 4..5 4..6 -1..1.5;\n    -4.. -3 -4.. -3 -4.. -3 1..2;\n    -5.. -4 2..3 -5.. -4 -1..0;\n    -1..0.1 0..1 1..2 -4..2.5]\n\nNow we can bound the eigenvalue set\n\nebox = eigenbox(A)\n\nTo get a qualitative evaluation of the enclosure, we can simulate the solution set of mathbfA using Montecarlo, as it is done in the following example\n\nusing Random; # hide\nRandom.seed!(42) # hide\nusing Plots\nN = 1000\n\nevalues = zeros(ComplexF64, 4, N)\n\nfor i in 1:N\n    evalues[:, i] = eigvals(rand.(A))\nend\n\nrpart = real.(evalues)\nipart = imag.(evalues)\n\nplot(IntervalBox(real(ebox), imag(ebox)); ratio=1, label=\"enclosure\")\nscatter!(rpart[1, :], ipart[1, :]; label=\"λ₁\")\nscatter!(rpart[2, :], ipart[2, :]; label=\"λ₂\")\nscatter!(rpart[3, :], ipart[3, :]; label=\"λ₃\")\nscatter!(rpart[4, :], ipart[4, :]; label=\"λ₄\")\nxlabel!(\"real\")\nylabel!(\"imag\")\nsavefig(\"eigs.png\") # hide\n\n(Image: )\n\nInternally, the generical interval eigenvalue problem is reduced to a real symmetric interval eigenvalue problem, as described in [HLA13]. It is good to remind that a real symmetric matrix has only real eigenvalues. The real symmetric interval eigenvalue problem can be solved in two ways\n\nRohn method – (default one) computes an enclosure of the eigenvalues set for the symmetric interval matrix. This is fast but the enclosure can be strictly larger than the hull\nHertz method – computes the exact hull of the eigenvalues for the symmetric interval matrix. Generally, these leads to tigher bounds, but it has exponential complexity, so it will be unfeasible for big matrices.\n\nThe function eigenbox can take a second optional parameter (Rohn() by default) to specify what algorithm to use for the real symmetric interval eigenvalue problem. The following example bounds the eigenvalues of the previous matrix using Hertz(), as can be noticed by the figure below, the Hertz method gives a tighter bound on the eigenvalues set.\n\neboxhertz = eigenbox(A, Hertz())\n\nplot(IntervalBox(real(ebox), imag(ebox)); ratio=1, label=\"enclosure\")\nplot!(IntervalBox(real(eboxhertz), imag(eboxhertz)); label=\"Hertz enclosure\", color=\"#00FF00\") # hide\nscatter!(rpart[1, :], ipart[1, :]; label=\"λ₁\") # hide\nscatter!(rpart[2, :], ipart[2, :]; label=\"λ₂\") # hide\nscatter!(rpart[3, :], ipart[3, :]; label=\"λ₃\") # hide\nscatter!(rpart[4, :], ipart[4, :]; label=\"λ₄\") # hide\nxlabel!(\"real\")\nylabel!(\"imag\")\nsavefig(\"eigs2.png\") # hide\n\n(Image: )","category":"section"},{"location":"tutorials/eigenvalues/#Verified-floating-point-computations-of-eigenvalues","page":"Eigenvalue computations","title":"Verified floating point computations of eigenvalues","text":"In the previous section we considered the problem of finding the eigenvalue set (or an enclosure of it) of an interval matrix. In this section, we consider the problem of computing eigenvalues and eigenvectors of a floating point matrix rigorously, that is we want to find an enclosure of the true eigenvalues and eigenvectors of the matrix. In IntervalLinearAlgebra.jl this is achieved using the verify_eigen function, as the following example demonstrates.\n\nA = [1 2; 3 4]\nevals, evecs, cert = verify_eigen(A)\nevals\n\nevecs\n\ncert\n\nIf called with only one input verify_eigen will first compute an approximate solution for the eigenvalues and eigenvectors of A and use that to find a rigorous bounding on the true eigenvalues and eigenvectors of the matrix. It is also possible to give the function the scalar parameters lambda and vecv, in which case it will compute a rigorous bound only for the specified eigenvalue lambda and eigenvector vecv. The last output of the function is a vector of boolean certificates, if the ith element is set to true, then the enclosure of the ith eigenvalue and eigenvector is rigorous, that is the algorithm could prove that that enclosure contains the true eigenvalue and eigenvector of A. If the certificate is false, then the algorithm could not prove the validity of the enclosure.\n\nThe function also accepts interval inputs. This is handy if the input matrix elements cannot be represented exactly as floating point numbers. Note however that this is meant only for interval matrices with very small intervals. If you have larger intervals, you should use the function of the previous section.\n\nTo test the function, let us consider the following example. First we generate random eigenvalues and eigenvectors\n\nev = sort(randn(5))\nD = Diagonal(ev)\nP = randn(5, 5)\nPinv, _ = epsilon_inflation(P, Diagonal(ones(5)))\nA = interval.(P) * D * Pinv\n\nNow we obtained an interval matrix mathbfA so that ev and P are eigenvalues and eigenvectors of some AinmathbfA. Note that P^-1 had to be computed rigorously using epsilon_inflation. Now we can compute its eigenvalues and eigenvectors and verify that the enclosures contain the true values.\n\nevals, evecs, cert = verify_eigen(A)\nevals\n\nevecs\n\ncert\n\nev .∈ evals\n\nNote also that despite the original eigenvalues and eigenvectors were real, the returned enclosures are complex. This is because any infinitesimally small perturbation in the elements of A may cause the eigenvalues to move away from the real line. For this reason, unless the matrix has some special structure that guarantees the eigenvalues are real (e.g. symmetric matrices), a valid enclosure should always be complex.\n\nFinally, the concept of enclosure of eigenvector may feel confusing, since eigenvectors are unique up to scale. This scale ambiguity is resolved by starting with the approximate eigenvector computed by normal linear algebra routines and fixing the element with the highest magnitude. \n\ncomplex_diam(x) = max(diam(real(x)), diam(imag(x)))\n\ncomplex_diam.(evecs)\n\nAs can be seen, for each eigenvector there's an interval with zero width, since to resolve scale ambiguity one non-zero element can be freely chosen (assuming eigenvalues have algebraic multiplicity 1). After that, the eigenvector is fixed and it makes sense to talk about enclosures of the other elements.","category":"section"},{"location":"api/solve/#General-inteface-for-solving-interval-linear-systems","page":"Solver interface","title":"General inteface for solving interval linear systems","text":"","category":"section"},{"location":"api/solve/#CommonSolve.solve","page":"Solver interface","title":"CommonSolve.solve","text":"solve(A::AbstractMatrix{T},\n      b::AbstractVector{T},\n      solver::AbstractIterativeSolver,\n      [precondition]::AbstractPrecondition=_default_precondition(A, solver),\n      [X]::AbstractVector{T}=enclose(A, b)) where {T<:Interval}\n\nSolves the square interval system Ax=b using the given algorithm, preconditioner and initial enclosure\n\nInput\n\nA – square interval matrix\nb – interval vector\nsolver – algorithm used to solve the linear system\nprecondition – preconditioner used. If not given, it is automatically computed based on                   the matrix A and the solver.\nX – initial enclosure.        if not given, it is automatically computed using enclose\n\nExamples\n\njulia> A = [2..4 -1..1;-1..1 2..4]\n2×2 Matrix{Interval{Float64}}:\n  [2, 4]  [-1, 1]\n [-1, 1]   [2, 4]\n\njulia> b = [-2..2, -1..1]\n2-element Vector{Interval{Float64}}:\n [-2, 2]\n [-1, 1]\n\njulia> solve(A, b, GaussSeidel(), NoPrecondition(), [-10..10, -10..10])\n2-element Vector{Interval{Float64}}:\n [-1.66668, 1.66668]\n [-1.33334, 1.33334]\n\njulia> solve(A, b, GaussSeidel())\n2-element Vector{Interval{Float64}}:\n [-1.66667, 1.66667]\n [-1.33334, 1.33334]\n\n\n\n\n\nsolve(A::AbstractMatrix{T},\n      b::AbstractVector{T},\n      solver::AbstractDirectSolver,\n      [precondition]::AbstractPrecondition=_default_precondition(A, solver)) where\n      {T<:Interval}\n\nSolves the square interval system Ax=b using the given algorithm, preconditioner and initial enclosure\n\nInput\n\nA – square interval matrix\nb – interval vector\nsolver – algorithm used to solve the linear system\nprecondition – preconditioner used. If not given, it is automatically computed based on                   the matrix A and the solver.\n\nExamples\n\njulia> A = [2..4 -1..1;-1..1 2..4]\n2×2 Matrix{Interval{Float64}}:\n  [2, 4]  [-1, 1]\n [-1, 1]   [2, 4]\n\njulia> b = [-2..2, -1..1]\n2-element Vector{Interval{Float64}}:\n [-2, 2]\n [-1, 1]\n\njulia> solve(A, b, HansenBliekRohn(), InverseMidpoint())\n2-element Vector{Interval{Float64}}:\n [-1.66667, 1.66667]\n [-1.33334, 1.33334]\n\njulia> solve(A, b, HansenBliekRohn())\n2-element Vector{Interval{Float64}}:\n [-1.66667, 1.66667]\n [-1.33334, 1.33334]\n\n\n\n\n\nsolve(A::AbstractMatrix{T},\n      b::AbstractVector{T},\n      [solver]::AbstractLinearSolver,\n      [precondition]::AbstractPrecondition=_default_precondition(A, solver)) where\n      {T<:Interval}\n\nSolves the square interval system Ax=b using the given algorithm, preconditioner and initial enclosure\n\nInput\n\nA – square interval matrix\nb – interval vector\nsolver – algorithm used to solve the linear system. If not given,             GaussianElimination is used.\nprecondition – preconditioner used. If not given, it is automatically computed based on                   the matrix A and the solver.\n\nExamples\n\njulia> A = [2..4 -1..1;-1..1 2..4]\n2×2 Matrix{Interval{Float64}}:\n  [2, 4]  [-1, 1]\n [-1, 1]   [2, 4]\n\njulia> b = [-2..2, -1..1]\n2-element Vector{Interval{Float64}}:\n [-2, 2]\n [-1, 1]\n\njulia> solve(A, b)\n2-element Vector{Interval{Float64}}:\n [-1.66667, 1.66667]\n [-1.33334, 1.33334]\n\n\n\n\n\n","category":"function"},{"location":"api/epsilon_inflation/#Verified-real-linear-systems","page":"Verified real linear systems","title":"Verified real linear systems","text":"Pages = [\"epsilon_inflation.md\"]","category":"section"},{"location":"api/epsilon_inflation/#IntervalLinearAlgebra.epsilon_inflation-Union{Tuple{N}, Tuple{S}, Tuple{T}, Tuple{AbstractMatrix{T}, AbstractArray{S, N}}} where {T<:Real, S<:Real, N}","page":"Verified real linear systems","title":"IntervalLinearAlgebra.epsilon_inflation","text":"epsilon_inflation(A::AbstractMatrix{T}, b::AbstractArray{S, N};\n                  r=0.1, ϵ=1e-20, iter_max=20) where {T<:Real, S<:Real, N}\n\nepsilon_inflation(A::AbstractMatrix{T}, b::AbstractArray{S, N};\n                  r=0.1, ϵ=1e-20, iter_max=20) where {T<:Interval, S<:Interval, N}\n\nGives an enclosure of the solution of the square linear system Ax=b using the ϵ-inflation algorithm,  see algorithm 10.7 of [RUM10]\n\nInput\n\nA        – square matrix of size n × n\nb        – vector of length n or matrix of size n × m\nr        – relative inflation, default 10%\nϵ        – absolute inflation, default 1e-20\niter_max – maximum number of iterations\n\nOutput\n\nx    – enclosure of the solution of the linear system\ncert – Boolean flag, if cert==true, then x is certified to contain the true\n\nsolution of the linear system, if cert==false, then the algorithm could not prove that x actually contains the true solution.\n\nAlgorithm\n\nGiven the real system Ax=b and an approximate solution ̃x, we initialize x₀ = ̃x ̃x. At each iteration the algorithm computes the inflation\n\ny = xₖ * 1 - r 1 + r + -ϵ ϵ\n\nand the update\n\nxₖ₁ = Z + (I - CA)y,\n\nwhere Z = C(b - Ax₀) and C is an approximate inverse of A. If the condition xₖ₁  y is met, then xₖ₁ is a proved enclosure of A¹b and cert is set to true. If the condition is not met by the maximum number of iterations, the latest computed enclosure is returned, but cert is set to false, meaning the algorithm could not prove that the enclosure contains the true solution. For interval systems, ̃x is obtained considering the midpoint of A and b.\n\nNotes\n\nThis algorithm is meant for real linear systems, or interval systems with\n\nvery tiny intervals. For interval linear systems with wider intervals, see the solve function.\n\nExamples\n\njulia> A = [1 2;3 4]\n2×2 Matrix{Int64}:\n 1  2\n 3  4\n\njulia> b = A * ones(2)\n2-element Vector{Float64}:\n 3.0\n 7.0\n\njulia> x, cert = epsilon_inflation(A, b)\n(Interval{Float64}[[0.999999, 1.00001], [0.999999, 1.00001]], true)\n\njulia> ones(2) .∈ x\n2-element BitVector:\n 1\n 1\n\njulia> cert\ntrue\n\n\n\n\n\n","category":"method"},{"location":"","page":"Home","title":"Home","text":"(Image: )\n\n(Image: version)(Image: License: MIT)(Image: Build Status)(Image: Coverage)(Image: bibtex citation)(Image: zenodo doi)","category":"section"},{"location":"#Overview","page":"Home","title":"Overview","text":"This package contains routines to perform numerical linear algebra using interval arithmetic. This can be used both for rigorous computations and uncertainty propagation.\n\nAn first overview of the package was given at JuliaCon 2021, the slides are available here.\n\n<iframe style=\"width:560px; height:315px\" src=\"https://www.youtube.com/embed/fre0TKgLJwg\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>","category":"section"},{"location":"#Features","page":"Home","title":"Features","text":"note: Note\nThe package is still under active development and things evolve quickly (or at least should)\n\nenclosure of the solution of interval linear systems\nexact characterization of the solution set of interval linear systems using Oettli-Präger\nverified solution of floating point linear systems\nenclosure of eigenvalues of interval matrices\nverified computation of eigenvalues and eigenvectors of floating point matrices","category":"section"},{"location":"#Installation","page":"Home","title":"Installation","text":"Open a Julia session and enter\n\nusing Pkg; Pkg.add(\"IntervalLinearAlgebra\")\n\nthis will download the package and all the necessary dependencies for you. Next you can import the package with\n\nusing IntervalLinearAlgebra\n\nand you are ready to go.","category":"section"},{"location":"#Quickstart","page":"Home","title":"Quickstart","text":"using IntervalLinearAlgebra, LazySets, Plots\n\nA = [2..4 -1..1; -1..1 2..4]\nb = [-2..2, -1..1]\n\nXenclose = solve(A, b)\npolytopes = solve(A, b, LinearOettliPrager())\n\nplot(UnionSetArray(polytopes), ratio=1, label=\"solution set\", legend=:top)\nplot!(IntervalBox(Xenclose), label=\"enclosure\")\n\n(Image: quickstart-example)","category":"section"},{"location":"#Citation","page":"Home","title":"Citation","text":"If you use this package in your work, please cite it as\n\n@software{ferranti2021interval,\nauthor = {\n            Luca Feranti and\n            Marcelo Forets and\n            David P. Sanders\n         },\ntitle  = {IntervalLinearAlgebra.jl: linear algebra done rigorously},\nmonth  = {9},\nyear   = {2021},\ndoi    = {10.5281/zenodo.5363563},\nurl    = {https://github.com/juliaintervals/IntervalLinearAlgebra.jl}\n}","category":"section"},{"location":"api/algorithms/#Algorithms","page":"Interval linear systems","title":"Algorithms","text":"Algorithms used to solve interval linear systems.\n\nPages=[\"algorithms.md\"]","category":"section"},{"location":"api/algorithms/#Enclosure-computation","page":"Interval linear systems","title":"Enclosure computation","text":"","category":"section"},{"location":"api/algorithms/#Direct-methods","page":"Interval linear systems","title":"Direct methods","text":"","category":"section"},{"location":"api/algorithms/#Iterative-methods","page":"Interval linear systems","title":"Iterative methods","text":"","category":"section"},{"location":"api/algorithms/#Exact-characterization","page":"Interval linear systems","title":"Exact characterization","text":"","category":"section"},{"location":"api/algorithms/#Parametric-Solvers","page":"Interval linear systems","title":"Parametric Solvers","text":"","category":"section"},{"location":"api/algorithms/#Direct-Methods","page":"Interval linear systems","title":"Direct Methods","text":"","category":"section"},{"location":"api/algorithms/#IntervalLinearAlgebra.GaussianElimination","page":"Interval linear systems","title":"IntervalLinearAlgebra.GaussianElimination","text":"GaussianElimination <: AbstractDirectSolver\n\nType for the Gaussian elimination solver of the square interval linear system Ax=b. For more details see section 5.6.1 of [HOR19]\n\nNotes\n\nAn object of type GaussianElimination is a callable function with method\n  (ge::GaussianElimination)(A::AbstractMatrix{T},\n                            b::AbstractVector{T}) where {T<:Interval}\n\nExamples\n\njulia> A = [2..4 -1..1;-1..1 2..4]\n2×2 Matrix{Interval{Float64}}:\n  [2, 4]  [-1, 1]\n [-1, 1]   [2, 4]\n\njulia> b = [-2..2, -1..1]\n2-element Vector{Interval{Float64}}:\n [-2, 2]\n [-1, 1]\n\njulia> ge = GaussianElimination()\nGaussianElimination linear solver\n\njulia> ge(A, b)\n2-element Vector{Interval{Float64}}:\n [-1.66667, 1.66667]\n [-1.33334, 1.33334]\n\n\n\n\n\n","category":"type"},{"location":"api/algorithms/#IntervalLinearAlgebra.HansenBliekRohn","page":"Interval linear systems","title":"IntervalLinearAlgebra.HansenBliekRohn","text":"HansenBliekRohn <: AbstractDirectSolver\n\nType for the HansenBliekRohn solver of the square interval linear system Ax=b. For more details see section 5.6.2 of [HOR19]\n\nNotes\n\nHansen-Bliek-Rohn works with H-matrices without precondition and with strongly regular matrices using InverseMidpoint precondition\nIf the midpoint of A is a diagonal matrix, then the algorithm returns the exact hull.\nAn object of type Hansen-Bliek-Rohn is a callable function with method\n  (hbr::HansenBliekRohn)(A::AbstractMatrix{T},\n                         b::AbstractVector{T}) where {T<:Interval}\n\nExamples\n\njulia> A = [2..4 -1..1;-1..1 2..4]\n2×2 Matrix{Interval{Float64}}:\n  [2, 4]  [-1, 1]\n [-1, 1]   [2, 4]\n\njulia> b = [-2..2, -1..1]\n2-element Vector{Interval{Float64}}:\n [-2, 2]\n [-1, 1]\n\njulia> hbr = HansenBliekRohn()\nHansenBliekRohn linear solver\n\njulia> hbr(A, b)\n2-element Vector{Interval{Float64}}:\n [-1.66667, 1.66667]\n [-1.33334, 1.33334]\n\n\n\n\n\n","category":"type"},{"location":"api/algorithms/#IntervalLinearAlgebra.GaussSeidel","page":"Interval linear systems","title":"IntervalLinearAlgebra.GaussSeidel","text":"GaussSeidel <: AbstractIterativeSolver\n\nType for the Gauss-Seidel solver of the interval linear system Ax=b. For details see Section 5.7.4 of [HOR19]\n\nFields\n\nmax_iterations – maximum number of iterations (default 20)\natol           – absolute tolerance (default 0), if at some point xₖ - xₖ₁  atol                     (elementwise), then stop and return xₖ₁.                     If atol=0, then min(diam(A))*1e-5 is used.\n\nNotes\n\nAn object of type GaussSeidel is a function with method\n  (gs::GaussSeidel)(A::AbstractMatrix{T},\n                    b::AbstractVector{T},\n                    [x]::AbstractVector{T}=enclose(A, b)) where {T<:Interval}\nInput\nA   – N×N interval matrix\nb   – interval vector of length N\nx   – (optional) initial enclosure for the solution of Ax = b. If not given,          it is automatically computed using enclose\n\nExamples\n\njulia> A = [2..4 -1..1;-1..1 2..4]\n2×2 Matrix{Interval{Float64}}:\n  [2, 4]  [-1, 1]\n [-1, 1]   [2, 4]\n\njulia> b = [-2..2, -1..1]\n2-element Vector{Interval{Float64}}:\n [-2, 2]\n [-1, 1]\n\njulia> gs = GaussSeidel()\nGaussSeidel linear solver\nmax_iterations = 20\natol = 0.0\n\njulia> gs(A, b)\n2-element Vector{Interval{Float64}}:\n [-1.66668, 1.66668]\n [-1.33334, 1.33334]\n\n\n\n\n\n","category":"type"},{"location":"api/algorithms/#IntervalLinearAlgebra.Jacobi","page":"Interval linear systems","title":"IntervalLinearAlgebra.Jacobi","text":"Jacobi <: AbstractIterativeSolver\n\nType for the Jacobi solver of the interval linear system Ax=b. For details see Section 5.7.4 of [HOR19]\n\nFields\n\nmax_iterations – maximum number of iterations (default 20)\natol           – absolute tolerance (default 0), if at some point xₖ - xₖ₁  atol                     (elementwise), then stop and return xₖ₁.                     If atol=0, then min(diam(A))*1e-5 is used.\n\nNotes\n\nAn object of type Jacobi is a function with method\n  (jac::Jacobi)(A::AbstractMatrix{T},\n                b::AbstractVector{T},\n                [x]::AbstractVector{T}=enclose(A, b)) where {T<:Interval}\nInput\nA   – N×N interval matrix\nb   – interval vector of length N\nx   – (optional) initial enclosure for the solution of Ax = b. If not given,          it is automatically computed using enclose\n\nExamples\n\njulia> A = [2..4 -1..1;-1..1 2..4]\n2×2 Matrix{Interval{Float64}}:\n  [2, 4]  [-1, 1]\n [-1, 1]   [2, 4]\n\njulia> b = [-2..2, -1..1]\n2-element Vector{Interval{Float64}}:\n [-2, 2]\n [-1, 1]\n\njulia> jac = Jacobi()\nJacobi linear solver\nmax_iterations = 20\natol = 0.0\n\njulia> jac(A, b)\n2-element Vector{Interval{Float64}}:\n [-1.66668, 1.66668]\n [-1.33335, 1.33335]\n\n\n\n\n\n","category":"type"},{"location":"api/algorithms/#IntervalLinearAlgebra.LinearKrawczyk","page":"Interval linear systems","title":"IntervalLinearAlgebra.LinearKrawczyk","text":"LinearKrawczyk <: AbstractIterativeSolver\n\nType for the Krawczyk solver of the interval linear system Ax=b. For details see Section 5.7.3 of [HOR19]\n\nFields\n\nmax_iterations – maximum number of iterations (default 20)\natol           – absolute tolerance (default 0), if at some point xₖ - xₖ₁  atol                     (elementwise), then stop and return xₖ₁.                     If atol=0, then min(diam(A))*1e-5 is used.\n\nNotes\n\nAn object of type LinearKrawczyk is a function with method\n  (kra::LinearKrawczyk)(A::AbstractMatrix{T},\n                        b::AbstractVector{T},\n                        [x]::AbstractVector{T}=enclose(A, b)) where {T<:Interval}\nInput\nA   – N×N interval matrix\nb   – interval vector of length N\nx   – (optional) initial enclosure for the solution of Ax = b. If not given,          it is automatically computed using enclose\n\nExamples\n\njulia> A = [2..4 -1..1;-1..1 2..4]\n2×2 Matrix{Interval{Float64}}:\n  [2, 4]  [-1, 1]\n [-1, 1]   [2, 4]\n\njulia> b = [-2..2, -1..1]\n2-element Vector{Interval{Float64}}:\n [-2, 2]\n [-1, 1]\n\njulia> kra = LinearKrawczyk()\nLinearKrawczyk linear solver\nmax_iterations = 20\natol = 0.0\n\njulia> kra(A, b)\n2-element Vector{Interval{Float64}}:\n [-2, 2]\n [-2, 2]\n\n\n\n\n\n","category":"type"},{"location":"api/algorithms/#IntervalLinearAlgebra.LinearOettliPrager","page":"Interval linear systems","title":"IntervalLinearAlgebra.LinearOettliPrager","text":"LinearOettliPrager <: AbstractDirectSolver\n\nType for the OettliPrager solver of the interval linear system Ax=b. The solver first converts the system of interval equalities into a system of real inequalities using Oettli-Präger theorem [OET64] and then finds the feasible set by solving a LP problem in each orthant using LazySets.jl.\n\nNotes\n\nYou need to import LazySets.jl to use this functionality.\nAn object of type LinearOettliPrager is a function with methods\n  (op::LinearOettliPrager)(A::AbstractMatrix{T},\n                           b::AbstractVector{T}) where {T<:Interval}\nInput\nA   – N×N interval matrix\nb   – interval vector of length N\n\nExamples\n\njulia> A = [2..4 -2..1;-1..2 2..4]\n2×2 Matrix{Interval{Float64}}:\n  [2, 4]  [-2, 1]\n [-1, 2]   [2, 4]\n\njulia> b = [-2..2, -2..2]\n2-element Vector{Interval{Float64}}:\n [-2, 2]\n [-2, 2]\n\njulia> polytopes = solve(A, b, LinearOettliPrager());\n\njulia> typeof(polytopes)\nVector{HPolytope{Float64, SparseArrays.SparseVector{Float64, Int64}}}\n\n\n\n\n\n","category":"type"},{"location":"api/algorithms/#IntervalLinearAlgebra.NonLinearOettliPrager","page":"Interval linear systems","title":"IntervalLinearAlgebra.NonLinearOettliPrager","text":"NonLinearOettliPrager <: AbstractIterativeSolver\n\nType for the OettliPrager solver of the interval linear system Ax=b. The solver first converts the system of interval equalities into a system of real inequalities using Oettli-Präger theorem [OET64] and then finds the feasible set using the forward-backward contractor method [JAU14] implemented in IntervalConstraintProgramming.jl.\n\nFields\n\ntol – tolerance for the paving, default 0.01.\n\nNotes\n\nYou need to import IntervalConstraintProgramming.jl to use this functionality.\nAn object of type NonLinearOettliPrager is a function with methods\n  (op::NonLinearOettliPrager)(A::AbstractMatrix{T},\n                              b::AbstractVector{T},\n                              [X]::AbstractVector{T}=enclose(A, b)) where {T<:Interval}\n\n  (op::NonLinearOettliPrager)(A::AbstractMatrix{T},\n                              b::AbstractVector{T},\n                              X::IntervalBox) where {T<:Interval}\nInput\nA   – N×N interval matrix\nb   – interval vector of length N\nX   – (optional) initial enclosure for the solution of Ax = b. If not given,          it is automatically computed using enclose\n\nExamples\n\njulia> A = [2..4 -2..1;-1..2 2..4]\n2×2 Matrix{Interval{Float64}}:\n  [2, 4]  [-2, 1]\n [-1, 2]   [2, 4]\n\njulia> b = [-2..2, -2..2]\n2-element Vector{Interval{Float64}}:\n [-2, 2]\n [-2, 2]\n\njulia> solve(A, b, NonLinearOettliPrager(0.1))\nPaving:\n- tolerance ϵ = 0.1\n- inner approx. of length 1195\n- boundary approx. of length 823\n\n\n\n\n\n","category":"type"},{"location":"api/algorithms/#IntervalLinearAlgebra.Skalna06","page":"Interval linear systems","title":"IntervalLinearAlgebra.Skalna06","text":"Skalna06\n\nDirect solver for interval linear systems with affine-parametric dependency. For more information see [SKA06].\n\n\n\n\n\n","category":"type"}]
}
